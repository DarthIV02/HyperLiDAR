{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acb6a35-636a-40f0-88c4-fe96d208ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter\n",
    "import torch\n",
    "from datasets import LIST_DATASETS, Collate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import wandb\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c56493a-9864-4629-b228-487caaf00ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor:\n",
    "    def __init__(self, input_channels=5, feat_channels=768, depth=48, \n",
    "                 grid_shape=[[256, 256], [256, 32], [256, 32]], nb_class=16, layer_norm=True, \n",
    "                 device=torch.device(\"cpu\"), early_exit = 48, **kwargs):\n",
    "        self.model = Segmenter(\n",
    "            input_channels=input_channels,\n",
    "            feat_channels=feat_channels,\n",
    "            depth=depth,\n",
    "            grid_shape=grid_shape,\n",
    "            nb_class=nb_class, # class for prediction\n",
    "            #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "            layer_norm=layer_norm,\n",
    "        )\n",
    "\n",
    "        classif = torch.nn.Conv1d(\n",
    "            feat_channels, nb_class, 1 # So it fits 16 = nb_class but classifier is not used\n",
    "        )\n",
    "        torch.nn.init.constant_(classif.bias, 0)\n",
    "        torch.nn.init.constant_(classif.weight, 0)\n",
    "        self.model.classif = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(feat_channels),\n",
    "            classif,\n",
    "        )\n",
    "\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model.classif.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        def get_optimizer(parameters):\n",
    "            return torch.optim.AdamW(\n",
    "                parameters,\n",
    "                lr=0.001,\n",
    "                weight_decay=0.003,\n",
    "            )\n",
    "\n",
    "        optim = get_optimizer(self.model.parameters())\n",
    "        self.device = device\n",
    "        self.device_string = \"cuda:0\"\n",
    "        self.num_classes = nb_class\n",
    "        self.early_exit = early_exit\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "        # Load pretrained model\n",
    "        path_to_ckpt = path\n",
    "        checkpoint = torch.load(path_to_ckpt,\n",
    "            map_location=self.device_string)\n",
    "        state_dict = checkpoint[\"net\"]  # Adjust key as needed\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "            new_state_dict[new_key] = v\n",
    "\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "\n",
    "        print(\n",
    "            f\"Checkpoint loaded on {self.device_string}: {path_to_ckpt}\"\n",
    "        )\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            torch.cuda.set_device(self.device_string) # cuda:0\n",
    "            self.model = self.model.cuda(self.device_string) # cuda:0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward_model(self, it, batch):\n",
    "        pts = batch[\"points\"]\n",
    "        feat = batch[\"feat\"]\n",
    "        labels = batch[\"labels_orig\"]\n",
    "        cell_ind = batch[\"cell_ind\"]\n",
    "        occupied_cell = batch[\"occupied_cells\"]\n",
    "        neighbors_emb = batch[\"neighbors_emb\"]\n",
    "        if self.device_string != 'cpu':\n",
    "            feat = feat.cuda(0, non_blocking=True)\n",
    "            labels = labels.cuda(0, non_blocking=True)\n",
    "            batch[\"upsample\"] = [\n",
    "                up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "            ]\n",
    "            cell_ind = cell_ind.cuda(0, non_blocking=True)\n",
    "            occupied_cell = occupied_cell.cuda(0, non_blocking=True)\n",
    "            neighbors_emb = neighbors_emb.cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            with torch.autocast(\"cuda\", enabled=True):\n",
    "                # Logits\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(*net_inputs, self.early_exit)\n",
    "                    encode, tokens, out = out[0], out[1], out[2]\n",
    "                    pred_label = out.max(1)[1]\n",
    "\n",
    "                    # Only return samples that are not noise\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "                    where = labels != 255\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(*net_inputs, self.early_exit)\n",
    "                encode, tokens, out = out[0], out[1], out[2]\n",
    "                pred_label = out.max(1)[1]\n",
    "\n",
    "                # Only return samples that are not noise\n",
    "                where = labels != 255\n",
    "\n",
    "        pts = torch.tensor(pts[0]).to(self.device)\n",
    "        where = where.cpu()\n",
    "        return pts[where], tokens[0,:,where], labels[where], pred_label[0, where]\n",
    "\n",
    "    def test(self, loader, total_voxels):        \n",
    "        # Metric\n",
    "        miou = MulticlassJaccardIndex(num_classes=self.num_classes, average=None).to(self.device, non_blocking=True)\n",
    "        final_labels = torch.empty((total_voxels), device=self.device)\n",
    "        final_pred = torch.empty((total_voxels), device=self.device)\n",
    "        final_labels_sep = torch.empty((1, 90000), device=self.device)\n",
    "        final_feat_sep = torch.empty((1, 768, 90000), device=self.device)\n",
    "        final_soa_result_sep = torch.empty((1, 90000), device=self.device)\n",
    "        final_points_sep = torch.empty((1, 3, 90000), device=self.device)\n",
    "        num_voxels = []\n",
    "        \n",
    "        start_idx = 0\n",
    "        for it, batch in tqdm(enumerate(loader), desc=\"SoA testing\"):\n",
    "            pts, features, labels, soa_result = self.forward_model(it, batch)\n",
    "            shape_sample = labels.shape[0]\n",
    "            num_voxels.append(shape_sample)\n",
    "            labels_tensor = torch.reshape(torch.Tensor(labels), (1,shape_sample)).to(self.device)\n",
    "            feat_tensor = torch.reshape(torch.Tensor(features), (1,768,shape_sample)).to(self.device)\n",
    "            soa_tensor = torch.reshape(torch.Tensor(soa_result), (1,shape_sample)).to(self.device)\n",
    "            pts_tensor = torch.reshape(torch.Tensor(pts), (1,3,shape_sample)).to(self.device)\n",
    "            final_labels_sep = torch.concat((final_labels_sep, F.pad(input=labels_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_soa_result_sep = torch.concat((final_soa_result_sep, F.pad(input=soa_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_feat_sep = torch.concat((final_feat_sep, F.pad(input=feat_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_points_sep = torch.concat((final_points_sep, F.pad(input=pts_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            print(final_labels_sep.shape)\n",
    "            print(final_soa_result_sep.shape)\n",
    "            print(final_feat_sep.shape)\n",
    "            print(final_points_sep.shape)\n",
    "\n",
    "            #labels = labels.to(dtype = torch.int64, device = self.device, non_blocking=True)\n",
    "            #soa_result = soa_result.to(device=self.device, non_blocking=True)\n",
    "            #final_labels[start_idx:start_idx+shape_sample] = labels\n",
    "\n",
    "            #final_pred[start_idx:start_idx+shape_sample] = soa_result\n",
    "\n",
    "            #start_idx += shape_sample\n",
    "\n",
    "            if it == 50:\n",
    "                break\n",
    "\n",
    "        #final_labels = final_labels[:start_idx]\n",
    "        #final_pred = final_pred[:start_idx]\n",
    "\n",
    "        #print(\"================================\")\n",
    "\n",
    "        #print('Pred FE', final_pred, \"\\tShape: \", final_pred.shape)\n",
    "        #print('Label', final_labels, \"\\tShape: \", final_labels.shape)\n",
    "        #accuracy = miou(final_pred, final_labels)\n",
    "        #avg_acc = torch.mean(accuracy)\n",
    "        #print(f'accuracy: {accuracy}')\n",
    "        #print(f'avg acc: {avg_acc}')\n",
    "\n",
    "        #cm = confusion_matrix(pred_hd, first_label, labels=torch.Tensor(range(0,15)))\n",
    "        #print(\"Confusion matrix \\n\")\n",
    "        #print(cm)\n",
    "\n",
    "        #print(\"================================\")\n",
    "\n",
    "        return final_points_sep, final_labels_sep, final_soa_result_sep, final_feat_sep, num_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d153176-3499-4237-bcea-9f5b7b74f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29969/1350821209.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_kitti.pth\n"
     ]
    }
   ],
   "source": [
    "fe = Feature_Extractor(nb_class=19)\n",
    "fe.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_kitti.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eeb18eb4-68ba-4b21-aa59-77bd06f74f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using original split\n",
      "Using original split\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"rootdir\": '/root/main/dataset/semantickitti',\n",
    "    \"input_feat\": [\"intensity\", \"xyz\", \"radius\"],\n",
    "    \"voxel_size\": 0.1,\n",
    "    \"num_neighbors\": 16,\n",
    "    \"dim_proj\": [2, 1, 0],\n",
    "    \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "    \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "}\n",
    "\n",
    "# Get datatset\n",
    "DATASET = LIST_DATASETS.get('semantic_kitti')\n",
    "\n",
    "dataset_train = DATASET(\n",
    "    phase=\"train\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DATASET(\n",
    "    phase=\"val\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "num_classes = 19\n",
    "\n",
    "path_pretrained = '/root/main/ScaLR/saved_models/ckpt_last_kitti.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e79b6c1-4d7b-4a94-bb28-45ff709105c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(device=device),\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=Collate(device=device),\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac5c66e4-f4b2-4b37-998a-b7396055fef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 768, 90000])\n",
      "torch.Size([2, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:07,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 768, 90000])\n",
      "torch.Size([3, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:11,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 768, 90000])\n",
      "torch.Size([4, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:15,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 768, 90000])\n",
      "torch.Size([5, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:19,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 768, 90000])\n",
      "torch.Size([6, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:24,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 768, 90000])\n",
      "torch.Size([7, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:29,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 768, 90000])\n",
      "torch.Size([8, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:34,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 768, 90000])\n",
      "torch.Size([9, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:39,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 768, 90000])\n",
      "torch.Size([10, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:45,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 768, 90000])\n",
      "torch.Size([11, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:50,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 768, 90000])\n",
      "torch.Size([12, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [00:55,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 768, 90000])\n",
      "torch.Size([13, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [01:00,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 768, 90000])\n",
      "torch.Size([14, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [01:06,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 768, 90000])\n",
      "torch.Size([15, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:12,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 768, 90000])\n",
      "torch.Size([16, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 16it [01:19,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 768, 90000])\n",
      "torch.Size([17, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 17it [01:26,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 768, 90000])\n",
      "torch.Size([18, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 18it [01:33,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 768, 90000])\n",
      "torch.Size([19, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 19it [01:39,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 768, 90000])\n",
      "torch.Size([20, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 20it [01:47,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 768, 90000])\n",
      "torch.Size([21, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 21it [01:53,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 768, 90000])\n",
      "torch.Size([22, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 22it [02:02,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 768, 90000])\n",
      "torch.Size([23, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 23it [02:08,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 768, 90000])\n",
      "torch.Size([24, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 24it [02:16,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 768, 90000])\n",
      "torch.Size([25, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 25it [02:23,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 768, 90000])\n",
      "torch.Size([26, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 26it [02:30,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 768, 90000])\n",
      "torch.Size([27, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 27it [02:39,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 768, 90000])\n",
      "torch.Size([28, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 28it [02:47,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 768, 90000])\n",
      "torch.Size([29, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 29it [02:55,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 768, 90000])\n",
      "torch.Size([30, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 30it [03:04,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 768, 90000])\n",
      "torch.Size([31, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 31it [03:13,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 768, 90000])\n",
      "torch.Size([32, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 32it [03:21,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 768, 90000])\n",
      "torch.Size([33, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 33it [03:31,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 768, 90000])\n",
      "torch.Size([34, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 34it [03:41,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 768, 90000])\n",
      "torch.Size([35, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 35it [03:49,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 768, 90000])\n",
      "torch.Size([36, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 36it [03:59,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 768, 90000])\n",
      "torch.Size([37, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 37it [04:09,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 768, 90000])\n",
      "torch.Size([38, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 38it [04:17,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 768, 90000])\n",
      "torch.Size([39, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 39it [04:28,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 768, 90000])\n",
      "torch.Size([40, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 40it [04:39,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 768, 90000])\n",
      "torch.Size([41, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 41it [04:49,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 768, 90000])\n",
      "torch.Size([42, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 42it [05:00, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 768, 90000])\n",
      "torch.Size([43, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 43it [05:11, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 768, 90000])\n",
      "torch.Size([44, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 44it [05:21, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 768, 90000])\n",
      "torch.Size([45, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 45it [05:33, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 768, 90000])\n",
      "torch.Size([46, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 46it [05:46, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 768, 90000])\n",
      "torch.Size([47, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 47it [05:57, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 768, 90000])\n",
      "torch.Size([48, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 48it [06:08, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 768, 90000])\n",
      "torch.Size([49, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 49it [06:20, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 768, 90000])\n",
      "torch.Size([50, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:30, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 768, 90000])\n",
      "torch.Size([51, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:43,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 768, 90000])\n",
      "torch.Size([52, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pts, labels_train, soa_train, feat_train, vox_train = fe.test(train_loader, 50) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab55da7f-7081-48b3-9a77-d43fcea520e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46948, 50477, 55087, 47337, 33538, 53880, 62154, 58821, 56910, 59075,\n",
       "        61729, 55668, 47670, 62586, 51217, 70168, 46743, 73190, 50894, 55858,\n",
       "        47573, 72963, 38323, 53441, 47561, 52344, 46960, 51288, 54708, 53011,\n",
       "        52989, 50063, 54923, 46465, 52676, 50247, 54651, 41890, 55716, 68641,\n",
       "        44248, 51205, 55295, 50700, 41873, 56819, 69015, 38397, 44931, 35259,\n",
       "        63025])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(vox_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ebfe3a5b-21d7-4067-9f24-c0bead7c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels_train[1:], 'labels_train_semkitti.pt')\n",
    "torch.save(soa_train[1:], 'soa_train_semkitti.pt')\n",
    "torch.save(feat_train[1:], 'feat_train_semkitti.pt')\n",
    "torch.save(pts[1:], 'pts_train_semkitti.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79d03f98-c1c1-4d38-9caf-a8efd5f7edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(vox_train), 'voxels_train_semkitti.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e102fd65-f15f-459c-b161-b410ebd07d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 768, 90000])\n",
      "torch.Size([2, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:07,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 768, 90000])\n",
      "torch.Size([3, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:11,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 768, 90000])\n",
      "torch.Size([4, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:15,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 768, 90000])\n",
      "torch.Size([5, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:19,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 768, 90000])\n",
      "torch.Size([6, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:24,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 768, 90000])\n",
      "torch.Size([7, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:29,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 768, 90000])\n",
      "torch.Size([8, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:34,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 768, 90000])\n",
      "torch.Size([9, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:38,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 768, 90000])\n",
      "torch.Size([10, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:43,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 768, 90000])\n",
      "torch.Size([11, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:47,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 768, 90000])\n",
      "torch.Size([12, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [00:52,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 768, 90000])\n",
      "torch.Size([13, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [00:58,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 768, 90000])\n",
      "torch.Size([14, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [01:04,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 768, 90000])\n",
      "torch.Size([15, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:10,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 768, 90000])\n",
      "torch.Size([16, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 16it [01:16,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 768, 90000])\n",
      "torch.Size([17, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 17it [01:23,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 768, 90000])\n",
      "torch.Size([18, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 18it [01:29,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 768, 90000])\n",
      "torch.Size([19, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 19it [01:35,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 768, 90000])\n",
      "torch.Size([20, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 20it [01:42,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 768, 90000])\n",
      "torch.Size([21, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 21it [01:48,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 768, 90000])\n",
      "torch.Size([22, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 22it [01:56,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 768, 90000])\n",
      "torch.Size([23, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 23it [02:04,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 768, 90000])\n",
      "torch.Size([24, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 24it [02:12,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 768, 90000])\n",
      "torch.Size([25, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 25it [02:20,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 768, 90000])\n",
      "torch.Size([26, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 26it [02:38, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 768, 90000])\n",
      "torch.Size([27, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 27it [02:46,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 768, 90000])\n",
      "torch.Size([28, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 28it [02:55,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 768, 90000])\n",
      "torch.Size([29, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 29it [03:05,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 768, 90000])\n",
      "torch.Size([30, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 30it [03:13,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 768, 90000])\n",
      "torch.Size([31, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 31it [03:22,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 768, 90000])\n",
      "torch.Size([32, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 32it [03:31,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 768, 90000])\n",
      "torch.Size([33, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 33it [03:39,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 768, 90000])\n",
      "torch.Size([34, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 34it [03:50,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 768, 90000])\n",
      "torch.Size([35, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 35it [03:59,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 768, 90000])\n",
      "torch.Size([36, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 36it [04:09,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 768, 90000])\n",
      "torch.Size([37, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 37it [04:19,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 768, 90000])\n",
      "torch.Size([38, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 38it [04:30,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 768, 90000])\n",
      "torch.Size([39, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 39it [04:39,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 768, 90000])\n",
      "torch.Size([40, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 40it [04:50, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 768, 90000])\n",
      "torch.Size([41, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 41it [05:01, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 768, 90000])\n",
      "torch.Size([42, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 42it [05:11, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 768, 90000])\n",
      "torch.Size([43, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 43it [05:22, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 768, 90000])\n",
      "torch.Size([44, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 44it [05:34, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 768, 90000])\n",
      "torch.Size([45, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 45it [05:44, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 768, 90000])\n",
      "torch.Size([46, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 46it [05:57, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 768, 90000])\n",
      "torch.Size([47, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 47it [06:09, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 768, 90000])\n",
      "torch.Size([48, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 48it [06:20, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 768, 90000])\n",
      "torch.Size([49, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 49it [06:34, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 768, 90000])\n",
      "torch.Size([50, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:47, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 768, 90000])\n",
      "torch.Size([51, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:58,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 768, 90000])\n",
      "torch.Size([52, 3, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pts, labels, soa, feat, vox = fe.test(val_loader, 50) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "81fbd2fa-d395-4efb-a1f6-99c717031fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels[1:], 'labels_test_semkitti.pt')\n",
    "torch.save(soa[1:], 'soa_test_semkitti.pt')\n",
    "torch.save(feat[1:], 'feat_test_semkitti.pt')\n",
    "torch.save(torch.tensor(vox), 'voxels_test_semkitti.pt')\n",
    "torch.save(pts[1:], 'pts_test_semkitti.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe634d-d0cc-4eeb-bca0-17cc02945efb",
   "metadata": {},
   "source": [
    "# Check if the two models have the same weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baf51511-caba-4f91-a457-4a904b4a6aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0-47): 48 x ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1-2): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4-5): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7-8): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10-11): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13-14): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16-17): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19-20): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22-23): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25-26): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28-29): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31-32): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34-35): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37-38): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40-41): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43-44): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46-47): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Sequential(\n",
       "    (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv1d(768, 19, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemanticKitti\n",
    "fe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cdbb7b2-9119-4c90-91e9-11aeb14de3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15601/2784029278.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_scalr.pth\n"
     ]
    }
   ],
   "source": [
    "fe_2 = Feature_Extractor(nb_class=16)\n",
    "fe_2.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_scalr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90e63368-3695-4f70-81ed-105168fe0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights differ in classif.0.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "# Assuming `model1` and `model2` are your two models\n",
    "def compare_model_weights(model1: Module, model2: Module):\n",
    "    for (name1, param1), (name2, param2) in zip(model1.named_parameters(), model2.named_parameters()):\n",
    "        if name1 != name2:\n",
    "            print(f\"Parameter names differ: {name1} vs {name2}\")\n",
    "            return False\n",
    "        if not torch.equal(param1.data, param2.data):\n",
    "            print(f\"Weights differ in {name1}\")\n",
    "            return False\n",
    "    print(\"All weights are didentical!\")\n",
    "    return True\n",
    "\n",
    "# Call the function with your two models\n",
    "result = compare_model_weights(fe.model, fe_2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1863e301-8605-4873-a531-a968dd24c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,))\n",
    "F.pad(input=x, pad=(0, 5), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e0655-8b4c-43d6-a513-f9302434cb48",
   "metadata": {},
   "source": [
    "# See nuscenes number of voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4991e33-9325-4cb4-ae57-aa771da012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "voxels = np.load('/root/main/ScaLR/debug/nuscenes/num_voxels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615dc657-45fb-4825-a9c5-6626480f04c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18197., 16838., 18008., 17197., 17114., 16733., 17014., 16558.,\n",
       "       16587., 14200., 17857.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
