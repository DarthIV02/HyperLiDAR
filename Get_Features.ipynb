{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acb6a35-636a-40f0-88c4-fe96d208ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter\n",
    "import torch\n",
    "from datasets import LIST_DATASETS, Collate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import wandb\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4c56493a-9864-4629-b228-487caaf00ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor:\n",
    "    def __init__(self, input_channels=5, feat_channels=768, depth=48, \n",
    "                 grid_shape=[[256, 256], [256, 32], [256, 32]], nb_class=16, layer_norm=True, \n",
    "                 device=torch.device(\"cpu\"), early_exit = 48, **kwargs):\n",
    "        self.model = Segmenter(\n",
    "            input_channels=input_channels,\n",
    "            feat_channels=feat_channels,\n",
    "            depth=depth,\n",
    "            grid_shape=grid_shape,\n",
    "            nb_class=nb_class, # class for prediction\n",
    "            #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "            layer_norm=layer_norm,\n",
    "        )\n",
    "\n",
    "        classif = torch.nn.Conv1d(\n",
    "            feat_channels, nb_class, 1 # So it fits 16 = nb_class but classifier is not used\n",
    "        )\n",
    "        torch.nn.init.constant_(classif.bias, 0)\n",
    "        torch.nn.init.constant_(classif.weight, 0)\n",
    "        self.model.classif = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(feat_channels),\n",
    "            classif,\n",
    "        )\n",
    "\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model.classif.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        def get_optimizer(parameters):\n",
    "            return torch.optim.AdamW(\n",
    "                parameters,\n",
    "                lr=0.001,\n",
    "                weight_decay=0.003,\n",
    "            )\n",
    "\n",
    "        optim = get_optimizer(self.model.parameters())\n",
    "        self.device = device\n",
    "        self.device_string = \"cuda:0\"\n",
    "        self.num_classes = nb_class\n",
    "        self.early_exit = early_exit\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "        # Load pretrained model\n",
    "        path_to_ckpt = path\n",
    "        checkpoint = torch.load(path_to_ckpt,\n",
    "            map_location=self.device_string)\n",
    "        state_dict = checkpoint[\"net\"]  # Adjust key as needed\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "            new_state_dict[new_key] = v\n",
    "\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "\n",
    "        print(\n",
    "            f\"Checkpoint loaded on {self.device_string}: {path_to_ckpt}\"\n",
    "        )\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            torch.cuda.set_device(self.device_string) # cuda:0\n",
    "            self.model = self.model.cuda(self.device_string) # cuda:0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward_model(self, it, batch):\n",
    "        feat = batch[\"feat\"]\n",
    "        labels = batch[\"labels_orig\"]\n",
    "        cell_ind = batch[\"cell_ind\"]\n",
    "        occupied_cell = batch[\"occupied_cells\"]\n",
    "        neighbors_emb = batch[\"neighbors_emb\"]\n",
    "        if self.device_string != 'cpu':\n",
    "            feat = feat.cuda(0, non_blocking=True)\n",
    "            labels = labels.cuda(0, non_blocking=True)\n",
    "            batch[\"upsample\"] = [\n",
    "                up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "            ]\n",
    "            cell_ind = cell_ind.cuda(0, non_blocking=True)\n",
    "            occupied_cell = occupied_cell.cuda(0, non_blocking=True)\n",
    "            neighbors_emb = neighbors_emb.cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            with torch.autocast(\"cuda\", enabled=True):\n",
    "                # Logits\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(*net_inputs, self.early_exit)\n",
    "                    encode, tokens, out = out[0], out[1], out[2]\n",
    "                    pred_label = out.max(1)[1]\n",
    "\n",
    "                    # Only return samples that are not noise\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "                    where = labels != 255\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(*net_inputs, self.early_exit)\n",
    "                encode, tokens, out = out[0], out[1], out[2]\n",
    "                pred_label = out.max(1)[1]\n",
    "\n",
    "                # Only return samples that are not noise\n",
    "                where = labels != 255\n",
    "        \n",
    "        return tokens[0,:,where], labels[where], pred_label[0, where]\n",
    "\n",
    "    def test(self, loader, total_voxels):        \n",
    "        # Metric\n",
    "        miou = MulticlassJaccardIndex(num_classes=self.num_classes, average=None).to(self.device, non_blocking=True)\n",
    "        final_labels = torch.empty((total_voxels), device=self.device)\n",
    "        final_pred = torch.empty((total_voxels), device=self.device)\n",
    "        final_labels_sep = torch.empty((1, 90000), device=self.device)\n",
    "        final_feat_sep = torch.empty((1, 768, 90000), device=self.device)\n",
    "        final_soa_result_sep = torch.empty((1, 90000), device=self.device)\n",
    "        num_voxels = []\n",
    "        \n",
    "        start_idx = 0\n",
    "        for it, batch in tqdm(enumerate(loader), desc=\"SoA testing\"):\n",
    "            features, labels, soa_result = self.forward_model(it, batch)\n",
    "            shape_sample = labels.shape[0]\n",
    "            num_voxels.append(shape_sample)\n",
    "            labels_tensor = torch.reshape(torch.Tensor(labels), (1,shape_sample)).to(self.device)\n",
    "            feat_tensor = torch.reshape(torch.Tensor(features), (1,768,shape_sample)).to(self.device)\n",
    "            soa_tensor = torch.reshape(torch.Tensor(soa_result), (1,shape_sample)).to(self.device)\n",
    "            final_labels_sep = torch.concat((final_labels_sep, F.pad(input=labels_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_soa_result_sep = torch.concat((final_soa_result_sep, F.pad(input=soa_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_feat_sep = torch.concat((final_feat_sep, F.pad(input=feat_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            print(final_labels_sep.shape)\n",
    "            print(final_soa_result_sep.shape)\n",
    "            print(final_feat_sep.shape)\n",
    "\n",
    "            #labels = labels.to(dtype = torch.int64, device = self.device, non_blocking=True)\n",
    "            #soa_result = soa_result.to(device=self.device, non_blocking=True)\n",
    "            #final_labels[start_idx:start_idx+shape_sample] = labels\n",
    "\n",
    "            #final_pred[start_idx:start_idx+shape_sample] = soa_result\n",
    "\n",
    "            #start_idx += shape_sample\n",
    "\n",
    "            if it == 50:\n",
    "                break\n",
    "\n",
    "        #final_labels = final_labels[:start_idx]\n",
    "        #final_pred = final_pred[:start_idx]\n",
    "\n",
    "        #print(\"================================\")\n",
    "\n",
    "        #print('Pred FE', final_pred, \"\\tShape: \", final_pred.shape)\n",
    "        #print('Label', final_labels, \"\\tShape: \", final_labels.shape)\n",
    "        #accuracy = miou(final_pred, final_labels)\n",
    "        #avg_acc = torch.mean(accuracy)\n",
    "        #print(f'accuracy: {accuracy}')\n",
    "        #print(f'avg acc: {avg_acc}')\n",
    "\n",
    "        #cm = confusion_matrix(pred_hd, first_label, labels=torch.Tensor(range(0,15)))\n",
    "        #print(\"Confusion matrix \\n\")\n",
    "        #print(cm)\n",
    "\n",
    "        #print(\"================================\")\n",
    "\n",
    "        return final_labels_sep, final_soa_result_sep, final_feat_sep, num_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d153176-3499-4237-bcea-9f5b7b74f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15601/3459449429.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_kitti.pth\n"
     ]
    }
   ],
   "source": [
    "fe = Feature_Extractor(nb_class=19)\n",
    "fe.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_kitti.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "eeb18eb4-68ba-4b21-aa59-77bd06f74f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using original split\n",
      "Using original split\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"rootdir\": '/root/main/dataset/semantickitti',\n",
    "    \"input_feat\": [\"intensity\", \"xyz\", \"radius\"],\n",
    "    \"voxel_size\": 0.1,\n",
    "    \"num_neighbors\": 16,\n",
    "    \"dim_proj\": [2, 1, 0],\n",
    "    \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "    \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "}\n",
    "\n",
    "# Get datatset\n",
    "DATASET = LIST_DATASETS.get('semantic_kitti')\n",
    "\n",
    "dataset_train = DATASET(\n",
    "    phase=\"train\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DATASET(\n",
    "    phase=\"val\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "num_classes = 19\n",
    "\n",
    "path_pretrained = '/root/main/ScaLR/saved_models/ckpt_last_kitti.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1e79b6c1-4d7b-4a94-bb28-45ff709105c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(device=device),\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=Collate(device=device),\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ac5c66e4-f4b2-4b37-998a-b7396055fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:06,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:10,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:15,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:19,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:23,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:27,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:32,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:37,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:41,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:46,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [00:51,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [00:56,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [01:02,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:09,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 16it [01:15,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 17it [01:20,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 18it [01:26,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 19it [01:32,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 20it [01:38,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 21it [01:44,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 22it [01:50,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 23it [01:58,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 24it [02:05,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 25it [02:12,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 26it [02:19,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 27it [02:26,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 28it [02:34,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 29it [02:42,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 30it [02:50,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 31it [03:00,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 32it [03:08,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 33it [03:16,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 34it [03:24,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 35it [03:34,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 36it [03:43,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 37it [03:52,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 38it [04:01,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 39it [04:13,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 40it [04:22,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 41it [04:32,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 42it [04:42,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 43it [04:54, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 44it [05:05, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 45it [05:15, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 46it [05:24, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 47it [05:41, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 48it [05:57, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 49it [06:13, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:28, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [06:40,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels_train, soa_train, feat_train, vox_train = fe.test(train_loader, 100) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ab55da7f-7081-48b3-9a77-d43fcea520e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45386, 53275, 50217, 54035, 51308, 45999, 66412, 62733, 55477, 42461,\n",
       "        57880, 60917, 43948, 55134, 69967, 61196, 56461, 47053, 62017, 59713,\n",
       "        51132, 62565, 53736, 47119, 53611, 53769, 57546, 42828, 58247, 52887,\n",
       "        61488, 48703, 53838, 61625, 51337, 63321, 55908, 50490, 40522, 43882,\n",
       "        50450, 53736, 54146, 51391, 55712, 50906, 55875, 55776, 50223, 44826,\n",
       "        50274])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(vox_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ebfe3a5b-21d7-4067-9f24-c0bead7c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels_train[1:], 'labels_train_semkitti.pt')\n",
    "torch.save(soa_train[1:], 'soa_train_semkitti.pt')\n",
    "torch.save(feat_train[1:], 'feat_train_semkitti.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "79d03f98-c1c1-4d38-9caf-a8efd5f7edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(vox_train), 'voxels_train_semkitti.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e102fd65-f15f-459c-b161-b410ebd07d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:07,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:11,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:16,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:20,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:24,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:28,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:32,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:37,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:42,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:53,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [01:08,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [01:21, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [01:29,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:34,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 16it [01:41,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 90000])\n",
      "torch.Size([17, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 17it [01:47,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 90000])\n",
      "torch.Size([18, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 18it [01:55,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 90000])\n",
      "torch.Size([19, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 19it [02:01,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 90000])\n",
      "torch.Size([20, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 20it [02:06,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 90000])\n",
      "torch.Size([21, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 21it [02:16,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 90000])\n",
      "torch.Size([22, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 22it [02:23,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 90000])\n",
      "torch.Size([23, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 23it [02:33,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 90000])\n",
      "torch.Size([24, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 24it [02:42,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 90000])\n",
      "torch.Size([25, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 25it [02:49,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 90000])\n",
      "torch.Size([26, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 26it [03:00,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 90000])\n",
      "torch.Size([27, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 27it [03:09,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 90000])\n",
      "torch.Size([28, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 28it [03:20,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 90000])\n",
      "torch.Size([29, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 29it [03:28,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 90000])\n",
      "torch.Size([30, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 30it [03:43, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 90000])\n",
      "torch.Size([31, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 31it [04:03, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 90000])\n",
      "torch.Size([32, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 32it [04:19, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 90000])\n",
      "torch.Size([33, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 33it [04:30, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 90000])\n",
      "torch.Size([34, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 34it [04:38, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 90000])\n",
      "torch.Size([35, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 35it [04:47, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 90000])\n",
      "torch.Size([36, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 36it [05:00, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 90000])\n",
      "torch.Size([37, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 37it [05:09, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 90000])\n",
      "torch.Size([38, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 38it [05:22, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 90000])\n",
      "torch.Size([39, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 39it [05:36, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 90000])\n",
      "torch.Size([40, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 40it [05:46, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 90000])\n",
      "torch.Size([41, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 41it [06:01, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 90000])\n",
      "torch.Size([42, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 42it [06:15, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 90000])\n",
      "torch.Size([43, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 43it [06:28, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 90000])\n",
      "torch.Size([44, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 44it [06:39, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 90000])\n",
      "torch.Size([45, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 45it [06:49, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 90000])\n",
      "torch.Size([46, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 46it [07:04, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 90000])\n",
      "torch.Size([47, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 47it [07:17, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 90000])\n",
      "torch.Size([48, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 48it [07:30, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 90000])\n",
      "torch.Size([49, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 49it [07:42, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 90000])\n",
      "torch.Size([50, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [07:56, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 90000])\n",
      "torch.Size([51, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [08:10,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 90000])\n",
      "torch.Size([52, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels, soa, feat, vox = fe.test(val_loader, 100) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "81fbd2fa-d395-4efb-a1f6-99c717031fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels[1:], 'labels_test_semkitti.pt')\n",
    "torch.save(soa[1:], 'soa_test_semkitti.pt')\n",
    "torch.save(feat[1:], 'feat_test_semkitti.pt')\n",
    "torch.save(torch.tensor(vox), 'voxels_test_semkitti.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe634d-d0cc-4eeb-bca0-17cc02945efb",
   "metadata": {},
   "source": [
    "# Check if the two models have the same weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baf51511-caba-4f91-a457-4a904b4a6aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0-47): 48 x ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1-2): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4-5): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7-8): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10-11): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13-14): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16-17): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19-20): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22-23): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25-26): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28-29): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31-32): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34-35): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37-38): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40-41): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43-44): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46-47): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Sequential(\n",
       "    (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv1d(768, 19, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemanticKitti\n",
    "fe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cdbb7b2-9119-4c90-91e9-11aeb14de3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15601/2784029278.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_scalr.pth\n"
     ]
    }
   ],
   "source": [
    "fe_2 = Feature_Extractor(nb_class=16)\n",
    "fe_2.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_scalr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90e63368-3695-4f70-81ed-105168fe0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights differ in classif.0.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "# Assuming `model1` and `model2` are your two models\n",
    "def compare_model_weights(model1: Module, model2: Module):\n",
    "    for (name1, param1), (name2, param2) in zip(model1.named_parameters(), model2.named_parameters()):\n",
    "        if name1 != name2:\n",
    "            print(f\"Parameter names differ: {name1} vs {name2}\")\n",
    "            return False\n",
    "        if not torch.equal(param1.data, param2.data):\n",
    "            print(f\"Weights differ in {name1}\")\n",
    "            return False\n",
    "    print(\"All weights are didentical!\")\n",
    "    return True\n",
    "\n",
    "# Call the function with your two models\n",
    "result = compare_model_weights(fe.model, fe_2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1863e301-8605-4873-a531-a968dd24c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,))\n",
    "F.pad(input=x, pad=(0, 5), mode='constant', value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
