{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acb6a35-636a-40f0-88c4-fe96d208ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter\n",
    "import torch\n",
    "from datasets import LIST_DATASETS, Collate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import wandb\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4c56493a-9864-4629-b228-487caaf00ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor:\n",
    "    def __init__(self, input_channels=5, feat_channels=768, depth=48, \n",
    "                 grid_shape=[[256, 256], [256, 32], [256, 32]], nb_class=16, layer_norm=True, \n",
    "                 device=torch.device(\"cpu\"), early_exit = 48, **kwargs):\n",
    "        self.model = Segmenter(\n",
    "            input_channels=input_channels,\n",
    "            feat_channels=feat_channels,\n",
    "            depth=depth,\n",
    "            grid_shape=grid_shape,\n",
    "            nb_class=nb_class, # class for prediction\n",
    "            #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "            layer_norm=layer_norm,\n",
    "        )\n",
    "\n",
    "        classif = torch.nn.Conv1d(\n",
    "            feat_channels, nb_class, 1 # So it fits 16 = nb_class but classifier is not used\n",
    "        )\n",
    "        torch.nn.init.constant_(classif.bias, 0)\n",
    "        torch.nn.init.constant_(classif.weight, 0)\n",
    "        self.model.classif = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(feat_channels),\n",
    "            classif,\n",
    "        )\n",
    "\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model.classif.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        def get_optimizer(parameters):\n",
    "            return torch.optim.AdamW(\n",
    "                parameters,\n",
    "                lr=0.001,\n",
    "                weight_decay=0.003,\n",
    "            )\n",
    "\n",
    "        optim = get_optimizer(self.model.parameters())\n",
    "        self.device = device\n",
    "        self.device_string = \"cuda:0\"\n",
    "        self.num_classes = nb_class\n",
    "        self.early_exit = early_exit\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "        # Load pretrained model\n",
    "        path_to_ckpt = path\n",
    "        checkpoint = torch.load(path_to_ckpt,\n",
    "            map_location=self.device_string)\n",
    "        state_dict = checkpoint[\"net\"]  # Adjust key as needed\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "            new_state_dict[new_key] = v\n",
    "\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "\n",
    "        print(\n",
    "            f\"Checkpoint loaded on {self.device_string}: {path_to_ckpt}\"\n",
    "        )\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            torch.cuda.set_device(self.device_string) # cuda:0\n",
    "            self.model = self.model.cuda(self.device_string) # cuda:0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward_model(self, it, batch):\n",
    "        feat = batch[\"feat\"]\n",
    "        labels = batch[\"labels_orig\"]\n",
    "        cell_ind = batch[\"cell_ind\"]\n",
    "        occupied_cell = batch[\"occupied_cells\"]\n",
    "        neighbors_emb = batch[\"neighbors_emb\"]\n",
    "        if self.device_string != 'cpu':\n",
    "            feat = feat.cuda(0, non_blocking=True)\n",
    "            labels = labels.cuda(0, non_blocking=True)\n",
    "            batch[\"upsample\"] = [\n",
    "                up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "            ]\n",
    "            cell_ind = cell_ind.cuda(0, non_blocking=True)\n",
    "            occupied_cell = occupied_cell.cuda(0, non_blocking=True)\n",
    "            neighbors_emb = neighbors_emb.cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            with torch.autocast(\"cuda\", enabled=True):\n",
    "                # Logits\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(*net_inputs, self.early_exit)\n",
    "                    encode, tokens, out = out[0], out[1], out[2]\n",
    "                    pred_label = out.max(1)[1]\n",
    "\n",
    "                    # Only return samples that are not noise\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "                    where = labels != 255\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(*net_inputs, self.early_exit)\n",
    "                encode, tokens, out = out[0], out[1], out[2]\n",
    "                pred_label = out.max(1)[1]\n",
    "\n",
    "                # Only return samples that are not noise\n",
    "                where = labels != 255\n",
    "        \n",
    "        return tokens[0,:,where], labels[where], pred_label[0, where]\n",
    "\n",
    "    def test(self, loader, total_voxels):        \n",
    "        # Metric\n",
    "        miou = MulticlassJaccardIndex(num_classes=self.num_classes, average=None).to(self.device, non_blocking=True)\n",
    "        final_labels = torch.empty((total_voxels), device=self.device)\n",
    "        final_pred = torch.empty((total_voxels), device=self.device)\n",
    "        final_labels_sep = torch.empty((1, 90000), device=self.device)\n",
    "        final_feat_sep = torch.empty((1, 768, 90000), device=self.device)\n",
    "        final_soa_result_sep = torch.empty((1, 90000), device=self.device)\n",
    "        num_voxels = []\n",
    "        \n",
    "        start_idx = 0\n",
    "        for it, batch in tqdm(enumerate(loader), desc=\"SoA testing\"):\n",
    "            features, labels, soa_result = self.forward_model(it, batch)\n",
    "            shape_sample = labels.shape[0]\n",
    "            num_voxels.append(shape_sample)\n",
    "            labels_tensor = torch.reshape(torch.Tensor(labels), (1,shape_sample)).to(self.device)\n",
    "            feat_tensor = torch.reshape(torch.Tensor(features), (1,768,shape_sample)).to(self.device)\n",
    "            soa_tensor = torch.reshape(torch.Tensor(soa_result), (1,shape_sample)).to(self.device)\n",
    "            final_labels_sep = torch.concat((final_labels_sep, F.pad(input=labels_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_soa_result_sep = torch.concat((final_soa_result_sep, F.pad(input=soa_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            final_feat_sep = torch.concat((final_feat_sep, F.pad(input=feat_tensor, pad=(0, 90000 - shape_sample), mode='constant', value=0)))\n",
    "            print(final_labels_sep.shape)\n",
    "            print(final_soa_result_sep.shape)\n",
    "            print(final_feat_sep.shape)\n",
    "\n",
    "            labels = labels.to(dtype = torch.int64, device = self.device, non_blocking=True)\n",
    "            soa_result = soa_result.to(device=self.device, non_blocking=True)\n",
    "            final_labels[start_idx:start_idx+shape_sample] = labels\n",
    "\n",
    "            final_pred[start_idx:start_idx+shape_sample] = soa_result\n",
    "\n",
    "            start_idx += shape_sample\n",
    "\n",
    "            if it == 50:\n",
    "                break\n",
    "\n",
    "        final_labels = final_labels[:start_idx]\n",
    "        final_pred = final_pred[:start_idx]\n",
    "\n",
    "        print(\"================================\")\n",
    "\n",
    "        print('Pred FE', final_pred, \"\\tShape: \", final_pred.shape)\n",
    "        print('Label', final_labels, \"\\tShape: \", final_labels.shape)\n",
    "        accuracy = miou(final_pred, final_labels)\n",
    "        avg_acc = torch.mean(accuracy)\n",
    "        print(f'accuracy: {accuracy}')\n",
    "        print(f'avg acc: {avg_acc}')\n",
    "\n",
    "        #cm = confusion_matrix(pred_hd, first_label, labels=torch.Tensor(range(0,15)))\n",
    "        #print(\"Confusion matrix \\n\")\n",
    "        #print(cm)\n",
    "\n",
    "        print(\"================================\")\n",
    "\n",
    "        return final_labels_sep, final_soa_result_sep, final_feat_sep, num_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1d153176-3499-4237-bcea-9f5b7b74f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15601/1544020565.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_kitti.pth\n"
     ]
    }
   ],
   "source": [
    "fe = Feature_Extractor(nb_class=19)\n",
    "fe.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_kitti.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "eeb18eb4-68ba-4b21-aa59-77bd06f74f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using original split\n",
      "Using original split\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"rootdir\": '/root/main/dataset/semantickitti',\n",
    "    \"input_feat\": [\"intensity\", \"xyz\", \"radius\"],\n",
    "    \"voxel_size\": 0.1,\n",
    "    \"num_neighbors\": 16,\n",
    "    \"dim_proj\": [2, 1, 0],\n",
    "    \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "    \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "}\n",
    "\n",
    "# Get datatset\n",
    "DATASET = LIST_DATASETS.get('semantic_kitti')\n",
    "\n",
    "dataset_train = DATASET(\n",
    "    phase=\"train\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DATASET(\n",
    "    phase=\"val\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "num_classes = 19\n",
    "\n",
    "path_pretrained = '/root/main/ScaLR/saved_models/ckpt_last_kitti.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1e79b6c1-4d7b-4a94-bb28-45ff709105c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(device=device),\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=Collate(device=device),\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c66e4-f4b2-4b37-998a-b7396055fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 90000])\n",
      "torch.Size([2, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:06,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 90000])\n",
      "torch.Size([3, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:10,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 90000])\n",
      "torch.Size([4, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:13,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 90000])\n",
      "torch.Size([5, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:17,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 90000])\n",
      "torch.Size([6, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:20,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 90000])\n",
      "torch.Size([7, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:25,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 90000])\n",
      "torch.Size([8, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:30,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 90000])\n",
      "torch.Size([9, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:34,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 90000])\n",
      "torch.Size([10, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:39,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 90000])\n",
      "torch.Size([11, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:45,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 90000])\n",
      "torch.Size([12, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [00:50,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 90000])\n",
      "torch.Size([13, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [00:55,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 90000])\n",
      "torch.Size([14, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [01:00,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 90000])\n",
      "torch.Size([15, 768, 90000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:05,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 90000])\n",
      "torch.Size([16, 768, 90000])\n"
     ]
    }
   ],
   "source": [
    "labels_train, soa_train, feat_train, vox_train = fe.test(train_loader, 5500000) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ab55da7f-7081-48b3-9a77-d43fcea520e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44142, 44003, 59890, 40398, 41625, 53900, 45817, 56911, 51037, 53170,\n",
       "        59709, 43178, 53050, 62282, 44822, 53380, 45886, 47859, 57482, 57516,\n",
       "        54655, 46799, 61926, 50007, 60078, 60736, 70450, 59455, 33977, 54562,\n",
       "        43954, 41885, 58911, 51025, 64296, 47641, 61382, 61788, 42247, 52006,\n",
       "        47080, 58451, 59847, 52650, 33660, 55842, 54676, 44737, 56141, 64482,\n",
       "        52811, 55376, 67701, 48054, 51237, 54986, 43940, 54340, 54894, 27346,\n",
       "        48815, 57825, 60356, 49891, 58465, 50979, 53075, 53087, 51195, 46261,\n",
       "        53950, 54229, 52888, 52543, 46392, 53398, 61353, 59786, 55711, 58418,\n",
       "        57230, 58920, 58534, 49536, 43975, 58928, 52022, 53749, 56769, 48545,\n",
       "        58366, 48006, 56668, 61652, 47422, 46437, 54898, 48368, 62403, 49621])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(vox_train[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ebfe3a5b-21d7-4067-9f24-c0bead7c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels_train[1:], 'labels_train_semkitti.pt')\n",
    "torch.save(soa_train[1:], 'soa_train_semkitti.pt')\n",
    "torch.save(feat_train[1:], 'feat_train_semkitti.pt')\n",
    "torch.save(torch.tensor(vox_train[1:]), 'voxels_train_semkitti.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e102fd65-f15f-459c-b161-b410ebd07d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 1it [00:03,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 70000])\n",
      "torch.Size([2, 70000])\n",
      "torch.Size([2, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 2it [00:06,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 70000])\n",
      "torch.Size([3, 70000])\n",
      "torch.Size([3, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 3it [00:09,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 70000])\n",
      "torch.Size([4, 70000])\n",
      "torch.Size([4, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 4it [00:13,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 70000])\n",
      "torch.Size([5, 70000])\n",
      "torch.Size([5, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 5it [00:17,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 70000])\n",
      "torch.Size([6, 70000])\n",
      "torch.Size([6, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 6it [00:21,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 70000])\n",
      "torch.Size([7, 70000])\n",
      "torch.Size([7, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 7it [00:25,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 70000])\n",
      "torch.Size([8, 70000])\n",
      "torch.Size([8, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 8it [00:30,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 70000])\n",
      "torch.Size([9, 70000])\n",
      "torch.Size([9, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 9it [00:35,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 70000])\n",
      "torch.Size([10, 70000])\n",
      "torch.Size([10, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 10it [00:39,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 70000])\n",
      "torch.Size([11, 70000])\n",
      "torch.Size([11, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 11it [00:44,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 70000])\n",
      "torch.Size([12, 70000])\n",
      "torch.Size([12, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 12it [00:49,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 70000])\n",
      "torch.Size([13, 70000])\n",
      "torch.Size([13, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 13it [00:53,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 70000])\n",
      "torch.Size([14, 70000])\n",
      "torch.Size([14, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 14it [00:58,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 70000])\n",
      "torch.Size([15, 70000])\n",
      "torch.Size([15, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 15it [01:04,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 70000])\n",
      "torch.Size([16, 70000])\n",
      "torch.Size([16, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 16it [01:08,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 70000])\n",
      "torch.Size([17, 70000])\n",
      "torch.Size([17, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 17it [01:12,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 70000])\n",
      "torch.Size([18, 70000])\n",
      "torch.Size([18, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 18it [01:18,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 70000])\n",
      "torch.Size([19, 70000])\n",
      "torch.Size([19, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 19it [01:23,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 70000])\n",
      "torch.Size([20, 70000])\n",
      "torch.Size([20, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 20it [01:28,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 70000])\n",
      "torch.Size([21, 70000])\n",
      "torch.Size([21, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 21it [01:34,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 70000])\n",
      "torch.Size([22, 70000])\n",
      "torch.Size([22, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 22it [01:40,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 70000])\n",
      "torch.Size([23, 70000])\n",
      "torch.Size([23, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 23it [01:46,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 70000])\n",
      "torch.Size([24, 70000])\n",
      "torch.Size([24, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 24it [01:53,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 70000])\n",
      "torch.Size([25, 70000])\n",
      "torch.Size([25, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 25it [01:59,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 70000])\n",
      "torch.Size([26, 70000])\n",
      "torch.Size([26, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 26it [02:06,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 70000])\n",
      "torch.Size([27, 70000])\n",
      "torch.Size([27, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 27it [02:13,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 70000])\n",
      "torch.Size([28, 70000])\n",
      "torch.Size([28, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 28it [02:22,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 70000])\n",
      "torch.Size([29, 70000])\n",
      "torch.Size([29, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 29it [02:29,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 70000])\n",
      "torch.Size([30, 70000])\n",
      "torch.Size([30, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 30it [02:37,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 70000])\n",
      "torch.Size([31, 70000])\n",
      "torch.Size([31, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 31it [02:43,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 70000])\n",
      "torch.Size([32, 70000])\n",
      "torch.Size([32, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 32it [02:51,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 70000])\n",
      "torch.Size([33, 70000])\n",
      "torch.Size([33, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 33it [03:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 70000])\n",
      "torch.Size([34, 70000])\n",
      "torch.Size([34, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 34it [03:07,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 70000])\n",
      "torch.Size([35, 70000])\n",
      "torch.Size([35, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 35it [03:16,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 70000])\n",
      "torch.Size([36, 70000])\n",
      "torch.Size([36, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 36it [03:25,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 70000])\n",
      "torch.Size([37, 70000])\n",
      "torch.Size([37, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 37it [03:32,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 70000])\n",
      "torch.Size([38, 70000])\n",
      "torch.Size([38, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 38it [03:39,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 70000])\n",
      "torch.Size([39, 70000])\n",
      "torch.Size([39, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 39it [03:47,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 70000])\n",
      "torch.Size([40, 70000])\n",
      "torch.Size([40, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 40it [03:55,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 70000])\n",
      "torch.Size([41, 70000])\n",
      "torch.Size([41, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 41it [04:08,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 70000])\n",
      "torch.Size([42, 70000])\n",
      "torch.Size([42, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 42it [04:19,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43, 70000])\n",
      "torch.Size([43, 70000])\n",
      "torch.Size([43, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 43it [04:28,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 70000])\n",
      "torch.Size([44, 70000])\n",
      "torch.Size([44, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 44it [04:38,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 70000])\n",
      "torch.Size([45, 70000])\n",
      "torch.Size([45, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 45it [04:49, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 70000])\n",
      "torch.Size([46, 70000])\n",
      "torch.Size([46, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 46it [04:58,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 70000])\n",
      "torch.Size([47, 70000])\n",
      "torch.Size([47, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 47it [05:13, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 70000])\n",
      "torch.Size([48, 70000])\n",
      "torch.Size([48, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 48it [05:26, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 70000])\n",
      "torch.Size([49, 70000])\n",
      "torch.Size([49, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 49it [05:38, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 70000])\n",
      "torch.Size([50, 70000])\n",
      "torch.Size([50, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 50it [05:47, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 70000])\n",
      "torch.Size([51, 70000])\n",
      "torch.Size([51, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 51it [05:58, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 70000])\n",
      "torch.Size([52, 70000])\n",
      "torch.Size([52, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 52it [06:09, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([53, 70000])\n",
      "torch.Size([53, 70000])\n",
      "torch.Size([53, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 53it [06:21, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54, 70000])\n",
      "torch.Size([54, 70000])\n",
      "torch.Size([54, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 54it [06:31, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55, 70000])\n",
      "torch.Size([55, 70000])\n",
      "torch.Size([55, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 55it [06:42, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 70000])\n",
      "torch.Size([56, 70000])\n",
      "torch.Size([56, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 56it [06:52, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 70000])\n",
      "torch.Size([57, 70000])\n",
      "torch.Size([57, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 57it [07:03, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58, 70000])\n",
      "torch.Size([58, 70000])\n",
      "torch.Size([58, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 58it [07:14, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 70000])\n",
      "torch.Size([59, 70000])\n",
      "torch.Size([59, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 59it [07:26, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 70000])\n",
      "torch.Size([60, 70000])\n",
      "torch.Size([60, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 60it [07:37, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61, 70000])\n",
      "torch.Size([61, 70000])\n",
      "torch.Size([61, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 61it [07:50, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62, 70000])\n",
      "torch.Size([62, 70000])\n",
      "torch.Size([62, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 62it [08:01, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 70000])\n",
      "torch.Size([63, 70000])\n",
      "torch.Size([63, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 63it [08:14, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 70000])\n",
      "torch.Size([64, 70000])\n",
      "torch.Size([64, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 64it [08:25, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 70000])\n",
      "torch.Size([65, 70000])\n",
      "torch.Size([65, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 65it [08:39, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66, 70000])\n",
      "torch.Size([66, 70000])\n",
      "torch.Size([66, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 66it [08:51, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67, 70000])\n",
      "torch.Size([67, 70000])\n",
      "torch.Size([67, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 67it [09:04, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68, 70000])\n",
      "torch.Size([68, 70000])\n",
      "torch.Size([68, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 68it [09:17, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69, 70000])\n",
      "torch.Size([69, 70000])\n",
      "torch.Size([69, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 69it [09:31, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 70000])\n",
      "torch.Size([70, 70000])\n",
      "torch.Size([70, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 70it [09:44, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([71, 70000])\n",
      "torch.Size([71, 70000])\n",
      "torch.Size([71, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 71it [09:58, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 70000])\n",
      "torch.Size([72, 70000])\n",
      "torch.Size([72, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 72it [10:11, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73, 70000])\n",
      "torch.Size([73, 70000])\n",
      "torch.Size([73, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 73it [10:24, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([74, 70000])\n",
      "torch.Size([74, 70000])\n",
      "torch.Size([74, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 74it [10:38, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 70000])\n",
      "torch.Size([75, 70000])\n",
      "torch.Size([75, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 75it [10:53, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([76, 70000])\n",
      "torch.Size([76, 70000])\n",
      "torch.Size([76, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 76it [11:06, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77, 70000])\n",
      "torch.Size([77, 70000])\n",
      "torch.Size([77, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 77it [11:21, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78, 70000])\n",
      "torch.Size([78, 70000])\n",
      "torch.Size([78, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 78it [11:34, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79, 70000])\n",
      "torch.Size([79, 70000])\n",
      "torch.Size([79, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 79it [11:49, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 70000])\n",
      "torch.Size([80, 70000])\n",
      "torch.Size([80, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 80it [12:02, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 70000])\n",
      "torch.Size([81, 70000])\n",
      "torch.Size([81, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 81it [12:18, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82, 70000])\n",
      "torch.Size([82, 70000])\n",
      "torch.Size([82, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 82it [12:31, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83, 70000])\n",
      "torch.Size([83, 70000])\n",
      "torch.Size([83, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 83it [12:46, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84, 70000])\n",
      "torch.Size([84, 70000])\n",
      "torch.Size([84, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 84it [13:00, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 70000])\n",
      "torch.Size([85, 70000])\n",
      "torch.Size([85, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 85it [13:16, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([86, 70000])\n",
      "torch.Size([86, 70000])\n",
      "torch.Size([86, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 86it [13:31, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 70000])\n",
      "torch.Size([87, 70000])\n",
      "torch.Size([87, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 87it [13:46, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 70000])\n",
      "torch.Size([88, 70000])\n",
      "torch.Size([88, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 88it [14:00, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 70000])\n",
      "torch.Size([89, 70000])\n",
      "torch.Size([89, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 89it [14:15, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90, 70000])\n",
      "torch.Size([90, 70000])\n",
      "torch.Size([90, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 90it [14:29, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 70000])\n",
      "torch.Size([91, 70000])\n",
      "torch.Size([91, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 91it [14:44, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([92, 70000])\n",
      "torch.Size([92, 70000])\n",
      "torch.Size([92, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 92it [14:59, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93, 70000])\n",
      "torch.Size([93, 70000])\n",
      "torch.Size([93, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 93it [15:16, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([94, 70000])\n",
      "torch.Size([94, 70000])\n",
      "torch.Size([94, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 94it [15:31, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 70000])\n",
      "torch.Size([95, 70000])\n",
      "torch.Size([95, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 95it [15:48, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 70000])\n",
      "torch.Size([96, 70000])\n",
      "torch.Size([96, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 96it [16:03, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 70000])\n",
      "torch.Size([97, 70000])\n",
      "torch.Size([97, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 97it [16:19, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([98, 70000])\n",
      "torch.Size([98, 70000])\n",
      "torch.Size([98, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 98it [16:34, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99, 70000])\n",
      "torch.Size([99, 70000])\n",
      "torch.Size([99, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 99it [16:50, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 70000])\n",
      "torch.Size([100, 70000])\n",
      "torch.Size([100, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 100it [17:06, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101, 70000])\n",
      "torch.Size([101, 70000])\n",
      "torch.Size([101, 768, 70000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoA testing: 100it [17:25, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 70000])\n",
      "torch.Size([102, 70000])\n",
      "torch.Size([102, 768, 70000])\n",
      "================================\n",
      "Pred FE tensor([14., 14., 14.,  ..., 14., 14., 14.]) \tShape:  torch.Size([5416264])\n",
      "Label tensor([14., 14., 14.,  ..., 14., 14., 14.]) \tShape:  torch.Size([5416264])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: tensor([0.9212, 0.3168, 0.3117, 0.8122, 0.3878, 0.5392, 0.6542, 0.0000, 0.8718,\n",
      "        0.2367, 0.6637, 0.0035, 0.8606, 0.3714, 0.8657, 0.5617, 0.6887, 0.5033,\n",
      "        0.4813])\n",
      "avg acc: 0.5290325284004211\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "labels, soa, feat, vox = fe.test(val_loader, 5500000) # With the nuscenes hyperparameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe634d-d0cc-4eeb-bca0-17cc02945efb",
   "metadata": {},
   "source": [
    "# Check if the two models have the same weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baf51511-caba-4f91-a457-4a904b4a6aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0-47): 48 x ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1-2): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4-5): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7-8): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10-11): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13-14): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16-17): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19-20): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22-23): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25-26): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28-29): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31-32): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34-35): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37-38): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40-41): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43-44): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46-47): 2 x SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Sequential(\n",
       "    (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv1d(768, 19, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemanticKitti\n",
    "fe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cdbb7b2-9119-4c90-91e9-11aeb14de3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15601/2784029278.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_ckpt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_scalr.pth\n"
     ]
    }
   ],
   "source": [
    "fe_2 = Feature_Extractor(nb_class=16)\n",
    "fe_2.load_pretrained('/root/main/ScaLR/saved_models/ckpt_last_scalr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90e63368-3695-4f70-81ed-105168fe0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights differ in classif.0.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "# Assuming `model1` and `model2` are your two models\n",
    "def compare_model_weights(model1: Module, model2: Module):\n",
    "    for (name1, param1), (name2, param2) in zip(model1.named_parameters(), model2.named_parameters()):\n",
    "        if name1 != name2:\n",
    "            print(f\"Parameter names differ: {name1} vs {name2}\")\n",
    "            return False\n",
    "        if not torch.equal(param1.data, param2.data):\n",
    "            print(f\"Weights differ in {name1}\")\n",
    "            return False\n",
    "    print(\"All weights are didentical!\")\n",
    "    return True\n",
    "\n",
    "# Call the function with your two models\n",
    "result = compare_model_weights(fe.model, fe_2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1863e301-8605-4873-a531-a968dd24c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,))\n",
    "F.pad(input=x, pad=(0, 5), mode='constant', value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
