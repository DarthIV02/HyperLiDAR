{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b07837f-e476-4b32-819e-49fc89c2c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'waffleiron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwaffleiron\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmenter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Segmenter\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LIST_DATASETS, Collate\n",
      "File \u001b[0;32m/home/HyperLiDAR/models/waffleiron/__init__.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing torch.sparse_coo_tensor for 3D to 2D projection.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WaffleIron\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmenter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Segmenter\n\u001b[1;32m     37\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [WaffleIron, Segmenter]\n",
      "File \u001b[0;32m/home/HyperLiDAR/models/waffleiron/backbone.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwaffleiron\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WI_SCATTER_REDUCE\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WI_SCATTER_REDUCE:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper_projection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m projection_3d_to_2d_scatter_reduce \u001b[38;5;28;01mas\u001b[39;00m projection_3d_to_2d\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'waffleiron'"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter\n",
    "import torch\n",
    "from datasets import LIST_DATASETS, Collate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import argparse\n",
    "import wandb\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "device_string = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Segmenter(\n",
    "    input_channels=5,\n",
    "    feat_channels=768,\n",
    "    depth=48,\n",
    "    grid_shape=[[256, 256], [256, 32], [256, 32]],\n",
    "    nb_class=16, # class for prediction\n",
    "    #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "    layer_norm=True,\n",
    ")\n",
    "\n",
    "# Load pretrained model\n",
    "ckpt = torch.load('/root/main/ScaLR/saved_models/ckpt_last_scalr.pth', map_location=device_string) # cuda:0\n",
    "ckpt = ckpt[\"net\"]\n",
    "\n",
    "new_ckpt = {}\n",
    "for k in ckpt.keys():\n",
    "    if k.startswith(\"module\"):\n",
    "        if k.startswith(\"module.classif.0\"):\n",
    "            continue\n",
    "        elif k.startswith(\"module.classif.1\"):\n",
    "            new_ckpt[\"classif\" + k[len(\"module.classif.1\") :]] = ckpt[k]\n",
    "        else:\n",
    "            new_ckpt[k[len(\"module.\") :]] = ckpt[k]\n",
    "    else:\n",
    "        new_ckpt[k] = ckpt[k]\n",
    "\n",
    "model.load_state_dict(new_ckpt)\n",
    "\n",
    "if device_string != 'cpu':\n",
    "    torch.cuda.set_device(device_string) # cuda:0\n",
    "    model = model.cuda(device_string) # cuda:0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "kwargs = {\n",
    "        \"rootdir\": '/root/main/dataset/nuscenes',\n",
    "        \"input_feat\": [\"xyz\", \"intensity\", \"radius\"],\n",
    "        \"voxel_size\": 0.1,\n",
    "        \"num_neighbors\": 16,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "    }\n",
    "\n",
    "# Get datatset\n",
    "DATASET = LIST_DATASETS.get(\"nuscenes\")\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = DATASET(\n",
    "    phase=\"train\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "test_dataset = DATASET(\n",
    "    phase=\"val\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )\n",
    "\n",
    "DIMENSIONS = 10000\n",
    "FEAT_SIZE = 768\n",
    "NUM_LEVELS = 1000\n",
    "BATCH_SIZE = 1  # for GPUs with enough memory we can process multiple images at ones\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size, levels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.position = embeddings.Random(size, out_features)\n",
    "        self.value = embeddings.Level(levels, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sample_hv = torchhd.bind(self.position.weight, self.value(x))\n",
    "        sample_hv = torchhd.multiset(sample_hv)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "\n",
    "\n",
    "encode = Encoder(DIMENSIONS, FEAT_SIZE, NUM_LEVELS)\n",
    "encode = encode.to(device)\n",
    "\n",
    "num_classes = 16\n",
    "model_hd = Centroid(DIMENSIONS, num_classes)\n",
    "model_hd = model_hd.to(device)\n",
    "\n",
    "stop = 48\n",
    "\n",
    "def forward_model(it, batch, stop):\n",
    "    feat = batch[\"feat\"]\n",
    "    labels = batch[\"labels_orig\"]\n",
    "    cell_ind = batch[\"cell_ind\"]\n",
    "    occupied_cell = batch[\"occupied_cells\"]\n",
    "    neighbors_emb = batch[\"neighbors_emb\"]\n",
    "    if device_string != 'cpu':\n",
    "        feat = feat.cuda(0, non_blocking=True)\n",
    "        labels = labels.cuda(0, non_blocking=True)\n",
    "        batch[\"upsample\"] = [\n",
    "            up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "        ]\n",
    "        cell_ind = cell_ind.cuda(0, non_blocking=True)\n",
    "        occupied_cell = occupied_cell.cuda(0, non_blocking=True)\n",
    "        neighbors_emb = neighbors_emb.cuda(0, non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(feat, cell_ind, occupied_cell, neighbors_emb, stop)\n",
    "        embed, tokens = out[0][0], out[1][0]\n",
    "        embed = embed.transpose(0, 1)\n",
    "        tokens = tokens.transpose(0, 1)\n",
    "\n",
    "        labels_v = [[] for i in range(embed.shape[0])]\n",
    "        for i, vox in enumerate(batch[\"upsample\"][0]):\n",
    "            labels_v[vox].append(labels[i])\n",
    "        labels_v_single = []\n",
    "        for labels_ in labels_v:\n",
    "            lab_tens = torch.tensor(labels_)\n",
    "            most_common_value = torch.bincount(lab_tens).argmax()\n",
    "            labels_v_single.append(most_common_value)\n",
    "    \n",
    "    return tokens, labels_v_single\n",
    "\n",
    "for it, batch in enumerate(train_loader):\n",
    "    \n",
    "    # Network inputs\n",
    "    \n",
    "    tokens, labels_v_single = forward_model(it, batch, stop)\n",
    "\n",
    "    print(tokens, labels_v_single)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
