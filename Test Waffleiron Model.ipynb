{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd417ca",
   "metadata": {},
   "source": [
    "# Test WaffleIron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afc500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12df3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter(\n",
    "    input_channels=5,\n",
    "    feat_channels=768,\n",
    "    depth=48,\n",
    "    grid_shape=[[256, 256], [256, 32], [256, 32]],\n",
    "    nb_class=16, # class for prediction\n",
    "    #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "    layer_norm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7e82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "ckpt = torch.load('./saved_models/ckpt_last_scalr.pth', map_location=\"cuda:0\")\n",
    "ckpt = ckpt[\"net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4933ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['module.embed.norm.weight', 'module.embed.norm.bias', 'module.embed.norm.running_mean', 'module.embed.norm.running_var', 'module.embed.norm.num_batches_tracked', 'module.embed.conv1.weight', 'module.embed.conv1.bias', 'module.embed.conv2.0.weight', 'module.embed.conv2.0.bias', 'module.embed.conv2.0.running_mean', 'module.embed.conv2.0.running_var', 'module.embed.conv2.0.num_batches_tracked', 'module.embed.conv2.1.weight', 'module.embed.conv2.2.weight', 'module.embed.conv2.2.bias', 'module.embed.conv2.2.running_mean', 'module.embed.conv2.2.running_var', 'module.embed.conv2.2.num_batches_tracked', 'module.embed.conv2.4.weight', 'module.embed.final.weight', 'module.embed.final.bias', 'module.waffleiron.channel_mix.0.scale.weight', 'module.waffleiron.channel_mix.0.norm.weight', 'module.waffleiron.channel_mix.0.norm.bias', 'module.waffleiron.channel_mix.0.mlp.0.weight', 'module.waffleiron.channel_mix.0.mlp.0.bias', 'module.waffleiron.channel_mix.0.mlp.2.weight', 'module.waffleiron.channel_mix.0.mlp.2.bias', 'module.waffleiron.channel_mix.1.scale.weight', 'module.waffleiron.channel_mix.1.norm.weight', 'module.waffleiron.channel_mix.1.norm.bias', 'module.waffleiron.channel_mix.1.mlp.0.weight', 'module.waffleiron.channel_mix.1.mlp.0.bias', 'module.waffleiron.channel_mix.1.mlp.2.weight', 'module.waffleiron.channel_mix.1.mlp.2.bias', 'module.waffleiron.channel_mix.2.scale.weight', 'module.waffleiron.channel_mix.2.norm.weight', 'module.waffleiron.channel_mix.2.norm.bias', 'module.waffleiron.channel_mix.2.mlp.0.weight', 'module.waffleiron.channel_mix.2.mlp.0.bias', 'module.waffleiron.channel_mix.2.mlp.2.weight', 'module.waffleiron.channel_mix.2.mlp.2.bias', 'module.waffleiron.channel_mix.3.scale.weight', 'module.waffleiron.channel_mix.3.norm.weight', 'module.waffleiron.channel_mix.3.norm.bias', 'module.waffleiron.channel_mix.3.mlp.0.weight', 'module.waffleiron.channel_mix.3.mlp.0.bias', 'module.waffleiron.channel_mix.3.mlp.2.weight', 'module.waffleiron.channel_mix.3.mlp.2.bias', 'module.waffleiron.channel_mix.4.scale.weight', 'module.waffleiron.channel_mix.4.norm.weight', 'module.waffleiron.channel_mix.4.norm.bias', 'module.waffleiron.channel_mix.4.mlp.0.weight', 'module.waffleiron.channel_mix.4.mlp.0.bias', 'module.waffleiron.channel_mix.4.mlp.2.weight', 'module.waffleiron.channel_mix.4.mlp.2.bias', 'module.waffleiron.channel_mix.5.scale.weight', 'module.waffleiron.channel_mix.5.norm.weight', 'module.waffleiron.channel_mix.5.norm.bias', 'module.waffleiron.channel_mix.5.mlp.0.weight', 'module.waffleiron.channel_mix.5.mlp.0.bias', 'module.waffleiron.channel_mix.5.mlp.2.weight', 'module.waffleiron.channel_mix.5.mlp.2.bias', 'module.waffleiron.channel_mix.6.scale.weight', 'module.waffleiron.channel_mix.6.norm.weight', 'module.waffleiron.channel_mix.6.norm.bias', 'module.waffleiron.channel_mix.6.mlp.0.weight', 'module.waffleiron.channel_mix.6.mlp.0.bias', 'module.waffleiron.channel_mix.6.mlp.2.weight', 'module.waffleiron.channel_mix.6.mlp.2.bias', 'module.waffleiron.channel_mix.7.scale.weight', 'module.waffleiron.channel_mix.7.norm.weight', 'module.waffleiron.channel_mix.7.norm.bias', 'module.waffleiron.channel_mix.7.mlp.0.weight', 'module.waffleiron.channel_mix.7.mlp.0.bias', 'module.waffleiron.channel_mix.7.mlp.2.weight', 'module.waffleiron.channel_mix.7.mlp.2.bias', 'module.waffleiron.channel_mix.8.scale.weight', 'module.waffleiron.channel_mix.8.norm.weight', 'module.waffleiron.channel_mix.8.norm.bias', 'module.waffleiron.channel_mix.8.mlp.0.weight', 'module.waffleiron.channel_mix.8.mlp.0.bias', 'module.waffleiron.channel_mix.8.mlp.2.weight', 'module.waffleiron.channel_mix.8.mlp.2.bias', 'module.waffleiron.channel_mix.9.scale.weight', 'module.waffleiron.channel_mix.9.norm.weight', 'module.waffleiron.channel_mix.9.norm.bias', 'module.waffleiron.channel_mix.9.mlp.0.weight', 'module.waffleiron.channel_mix.9.mlp.0.bias', 'module.waffleiron.channel_mix.9.mlp.2.weight', 'module.waffleiron.channel_mix.9.mlp.2.bias', 'module.waffleiron.channel_mix.10.scale.weight', 'module.waffleiron.channel_mix.10.norm.weight', 'module.waffleiron.channel_mix.10.norm.bias', 'module.waffleiron.channel_mix.10.mlp.0.weight', 'module.waffleiron.channel_mix.10.mlp.0.bias', 'module.waffleiron.channel_mix.10.mlp.2.weight', 'module.waffleiron.channel_mix.10.mlp.2.bias', 'module.waffleiron.channel_mix.11.scale.weight', 'module.waffleiron.channel_mix.11.norm.weight', 'module.waffleiron.channel_mix.11.norm.bias', 'module.waffleiron.channel_mix.11.mlp.0.weight', 'module.waffleiron.channel_mix.11.mlp.0.bias', 'module.waffleiron.channel_mix.11.mlp.2.weight', 'module.waffleiron.channel_mix.11.mlp.2.bias', 'module.waffleiron.channel_mix.12.scale.weight', 'module.waffleiron.channel_mix.12.norm.weight', 'module.waffleiron.channel_mix.12.norm.bias', 'module.waffleiron.channel_mix.12.mlp.0.weight', 'module.waffleiron.channel_mix.12.mlp.0.bias', 'module.waffleiron.channel_mix.12.mlp.2.weight', 'module.waffleiron.channel_mix.12.mlp.2.bias', 'module.waffleiron.channel_mix.13.scale.weight', 'module.waffleiron.channel_mix.13.norm.weight', 'module.waffleiron.channel_mix.13.norm.bias', 'module.waffleiron.channel_mix.13.mlp.0.weight', 'module.waffleiron.channel_mix.13.mlp.0.bias', 'module.waffleiron.channel_mix.13.mlp.2.weight', 'module.waffleiron.channel_mix.13.mlp.2.bias', 'module.waffleiron.channel_mix.14.scale.weight', 'module.waffleiron.channel_mix.14.norm.weight', 'module.waffleiron.channel_mix.14.norm.bias', 'module.waffleiron.channel_mix.14.mlp.0.weight', 'module.waffleiron.channel_mix.14.mlp.0.bias', 'module.waffleiron.channel_mix.14.mlp.2.weight', 'module.waffleiron.channel_mix.14.mlp.2.bias', 'module.waffleiron.channel_mix.15.scale.weight', 'module.waffleiron.channel_mix.15.norm.weight', 'module.waffleiron.channel_mix.15.norm.bias', 'module.waffleiron.channel_mix.15.mlp.0.weight', 'module.waffleiron.channel_mix.15.mlp.0.bias', 'module.waffleiron.channel_mix.15.mlp.2.weight', 'module.waffleiron.channel_mix.15.mlp.2.bias', 'module.waffleiron.channel_mix.16.scale.weight', 'module.waffleiron.channel_mix.16.norm.weight', 'module.waffleiron.channel_mix.16.norm.bias', 'module.waffleiron.channel_mix.16.mlp.0.weight', 'module.waffleiron.channel_mix.16.mlp.0.bias', 'module.waffleiron.channel_mix.16.mlp.2.weight', 'module.waffleiron.channel_mix.16.mlp.2.bias', 'module.waffleiron.channel_mix.17.scale.weight', 'module.waffleiron.channel_mix.17.norm.weight', 'module.waffleiron.channel_mix.17.norm.bias', 'module.waffleiron.channel_mix.17.mlp.0.weight', 'module.waffleiron.channel_mix.17.mlp.0.bias', 'module.waffleiron.channel_mix.17.mlp.2.weight', 'module.waffleiron.channel_mix.17.mlp.2.bias', 'module.waffleiron.channel_mix.18.scale.weight', 'module.waffleiron.channel_mix.18.norm.weight', 'module.waffleiron.channel_mix.18.norm.bias', 'module.waffleiron.channel_mix.18.mlp.0.weight', 'module.waffleiron.channel_mix.18.mlp.0.bias', 'module.waffleiron.channel_mix.18.mlp.2.weight', 'module.waffleiron.channel_mix.18.mlp.2.bias', 'module.waffleiron.channel_mix.19.scale.weight', 'module.waffleiron.channel_mix.19.norm.weight', 'module.waffleiron.channel_mix.19.norm.bias', 'module.waffleiron.channel_mix.19.mlp.0.weight', 'module.waffleiron.channel_mix.19.mlp.0.bias', 'module.waffleiron.channel_mix.19.mlp.2.weight', 'module.waffleiron.channel_mix.19.mlp.2.bias', 'module.waffleiron.channel_mix.20.scale.weight', 'module.waffleiron.channel_mix.20.norm.weight', 'module.waffleiron.channel_mix.20.norm.bias', 'module.waffleiron.channel_mix.20.mlp.0.weight', 'module.waffleiron.channel_mix.20.mlp.0.bias', 'module.waffleiron.channel_mix.20.mlp.2.weight', 'module.waffleiron.channel_mix.20.mlp.2.bias', 'module.waffleiron.channel_mix.21.scale.weight', 'module.waffleiron.channel_mix.21.norm.weight', 'module.waffleiron.channel_mix.21.norm.bias', 'module.waffleiron.channel_mix.21.mlp.0.weight', 'module.waffleiron.channel_mix.21.mlp.0.bias', 'module.waffleiron.channel_mix.21.mlp.2.weight', 'module.waffleiron.channel_mix.21.mlp.2.bias', 'module.waffleiron.channel_mix.22.scale.weight', 'module.waffleiron.channel_mix.22.norm.weight', 'module.waffleiron.channel_mix.22.norm.bias', 'module.waffleiron.channel_mix.22.mlp.0.weight', 'module.waffleiron.channel_mix.22.mlp.0.bias', 'module.waffleiron.channel_mix.22.mlp.2.weight', 'module.waffleiron.channel_mix.22.mlp.2.bias', 'module.waffleiron.channel_mix.23.scale.weight', 'module.waffleiron.channel_mix.23.norm.weight', 'module.waffleiron.channel_mix.23.norm.bias', 'module.waffleiron.channel_mix.23.mlp.0.weight', 'module.waffleiron.channel_mix.23.mlp.0.bias', 'module.waffleiron.channel_mix.23.mlp.2.weight', 'module.waffleiron.channel_mix.23.mlp.2.bias', 'module.waffleiron.channel_mix.24.scale.weight', 'module.waffleiron.channel_mix.24.norm.weight', 'module.waffleiron.channel_mix.24.norm.bias', 'module.waffleiron.channel_mix.24.mlp.0.weight', 'module.waffleiron.channel_mix.24.mlp.0.bias', 'module.waffleiron.channel_mix.24.mlp.2.weight', 'module.waffleiron.channel_mix.24.mlp.2.bias', 'module.waffleiron.channel_mix.25.scale.weight', 'module.waffleiron.channel_mix.25.norm.weight', 'module.waffleiron.channel_mix.25.norm.bias', 'module.waffleiron.channel_mix.25.mlp.0.weight', 'module.waffleiron.channel_mix.25.mlp.0.bias', 'module.waffleiron.channel_mix.25.mlp.2.weight', 'module.waffleiron.channel_mix.25.mlp.2.bias', 'module.waffleiron.channel_mix.26.scale.weight', 'module.waffleiron.channel_mix.26.norm.weight', 'module.waffleiron.channel_mix.26.norm.bias', 'module.waffleiron.channel_mix.26.mlp.0.weight', 'module.waffleiron.channel_mix.26.mlp.0.bias', 'module.waffleiron.channel_mix.26.mlp.2.weight', 'module.waffleiron.channel_mix.26.mlp.2.bias', 'module.waffleiron.channel_mix.27.scale.weight', 'module.waffleiron.channel_mix.27.norm.weight', 'module.waffleiron.channel_mix.27.norm.bias', 'module.waffleiron.channel_mix.27.mlp.0.weight', 'module.waffleiron.channel_mix.27.mlp.0.bias', 'module.waffleiron.channel_mix.27.mlp.2.weight', 'module.waffleiron.channel_mix.27.mlp.2.bias', 'module.waffleiron.channel_mix.28.scale.weight', 'module.waffleiron.channel_mix.28.norm.weight', 'module.waffleiron.channel_mix.28.norm.bias', 'module.waffleiron.channel_mix.28.mlp.0.weight', 'module.waffleiron.channel_mix.28.mlp.0.bias', 'module.waffleiron.channel_mix.28.mlp.2.weight', 'module.waffleiron.channel_mix.28.mlp.2.bias', 'module.waffleiron.channel_mix.29.scale.weight', 'module.waffleiron.channel_mix.29.norm.weight', 'module.waffleiron.channel_mix.29.norm.bias', 'module.waffleiron.channel_mix.29.mlp.0.weight', 'module.waffleiron.channel_mix.29.mlp.0.bias', 'module.waffleiron.channel_mix.29.mlp.2.weight', 'module.waffleiron.channel_mix.29.mlp.2.bias', 'module.waffleiron.channel_mix.30.scale.weight', 'module.waffleiron.channel_mix.30.norm.weight', 'module.waffleiron.channel_mix.30.norm.bias', 'module.waffleiron.channel_mix.30.mlp.0.weight', 'module.waffleiron.channel_mix.30.mlp.0.bias', 'module.waffleiron.channel_mix.30.mlp.2.weight', 'module.waffleiron.channel_mix.30.mlp.2.bias', 'module.waffleiron.channel_mix.31.scale.weight', 'module.waffleiron.channel_mix.31.norm.weight', 'module.waffleiron.channel_mix.31.norm.bias', 'module.waffleiron.channel_mix.31.mlp.0.weight', 'module.waffleiron.channel_mix.31.mlp.0.bias', 'module.waffleiron.channel_mix.31.mlp.2.weight', 'module.waffleiron.channel_mix.31.mlp.2.bias', 'module.waffleiron.channel_mix.32.scale.weight', 'module.waffleiron.channel_mix.32.norm.weight', 'module.waffleiron.channel_mix.32.norm.bias', 'module.waffleiron.channel_mix.32.mlp.0.weight', 'module.waffleiron.channel_mix.32.mlp.0.bias', 'module.waffleiron.channel_mix.32.mlp.2.weight', 'module.waffleiron.channel_mix.32.mlp.2.bias', 'module.waffleiron.channel_mix.33.scale.weight', 'module.waffleiron.channel_mix.33.norm.weight', 'module.waffleiron.channel_mix.33.norm.bias', 'module.waffleiron.channel_mix.33.mlp.0.weight', 'module.waffleiron.channel_mix.33.mlp.0.bias', 'module.waffleiron.channel_mix.33.mlp.2.weight', 'module.waffleiron.channel_mix.33.mlp.2.bias', 'module.waffleiron.channel_mix.34.scale.weight', 'module.waffleiron.channel_mix.34.norm.weight', 'module.waffleiron.channel_mix.34.norm.bias', 'module.waffleiron.channel_mix.34.mlp.0.weight', 'module.waffleiron.channel_mix.34.mlp.0.bias', 'module.waffleiron.channel_mix.34.mlp.2.weight', 'module.waffleiron.channel_mix.34.mlp.2.bias', 'module.waffleiron.channel_mix.35.scale.weight', 'module.waffleiron.channel_mix.35.norm.weight', 'module.waffleiron.channel_mix.35.norm.bias', 'module.waffleiron.channel_mix.35.mlp.0.weight', 'module.waffleiron.channel_mix.35.mlp.0.bias', 'module.waffleiron.channel_mix.35.mlp.2.weight', 'module.waffleiron.channel_mix.35.mlp.2.bias', 'module.waffleiron.channel_mix.36.scale.weight', 'module.waffleiron.channel_mix.36.norm.weight', 'module.waffleiron.channel_mix.36.norm.bias', 'module.waffleiron.channel_mix.36.mlp.0.weight', 'module.waffleiron.channel_mix.36.mlp.0.bias', 'module.waffleiron.channel_mix.36.mlp.2.weight', 'module.waffleiron.channel_mix.36.mlp.2.bias', 'module.waffleiron.channel_mix.37.scale.weight', 'module.waffleiron.channel_mix.37.norm.weight', 'module.waffleiron.channel_mix.37.norm.bias', 'module.waffleiron.channel_mix.37.mlp.0.weight', 'module.waffleiron.channel_mix.37.mlp.0.bias', 'module.waffleiron.channel_mix.37.mlp.2.weight', 'module.waffleiron.channel_mix.37.mlp.2.bias', 'module.waffleiron.channel_mix.38.scale.weight', 'module.waffleiron.channel_mix.38.norm.weight', 'module.waffleiron.channel_mix.38.norm.bias', 'module.waffleiron.channel_mix.38.mlp.0.weight', 'module.waffleiron.channel_mix.38.mlp.0.bias', 'module.waffleiron.channel_mix.38.mlp.2.weight', 'module.waffleiron.channel_mix.38.mlp.2.bias', 'module.waffleiron.channel_mix.39.scale.weight', 'module.waffleiron.channel_mix.39.norm.weight', 'module.waffleiron.channel_mix.39.norm.bias', 'module.waffleiron.channel_mix.39.mlp.0.weight', 'module.waffleiron.channel_mix.39.mlp.0.bias', 'module.waffleiron.channel_mix.39.mlp.2.weight', 'module.waffleiron.channel_mix.39.mlp.2.bias', 'module.waffleiron.channel_mix.40.scale.weight', 'module.waffleiron.channel_mix.40.norm.weight', 'module.waffleiron.channel_mix.40.norm.bias', 'module.waffleiron.channel_mix.40.mlp.0.weight', 'module.waffleiron.channel_mix.40.mlp.0.bias', 'module.waffleiron.channel_mix.40.mlp.2.weight', 'module.waffleiron.channel_mix.40.mlp.2.bias', 'module.waffleiron.channel_mix.41.scale.weight', 'module.waffleiron.channel_mix.41.norm.weight', 'module.waffleiron.channel_mix.41.norm.bias', 'module.waffleiron.channel_mix.41.mlp.0.weight', 'module.waffleiron.channel_mix.41.mlp.0.bias', 'module.waffleiron.channel_mix.41.mlp.2.weight', 'module.waffleiron.channel_mix.41.mlp.2.bias', 'module.waffleiron.channel_mix.42.scale.weight', 'module.waffleiron.channel_mix.42.norm.weight', 'module.waffleiron.channel_mix.42.norm.bias', 'module.waffleiron.channel_mix.42.mlp.0.weight', 'module.waffleiron.channel_mix.42.mlp.0.bias', 'module.waffleiron.channel_mix.42.mlp.2.weight', 'module.waffleiron.channel_mix.42.mlp.2.bias', 'module.waffleiron.channel_mix.43.scale.weight', 'module.waffleiron.channel_mix.43.norm.weight', 'module.waffleiron.channel_mix.43.norm.bias', 'module.waffleiron.channel_mix.43.mlp.0.weight', 'module.waffleiron.channel_mix.43.mlp.0.bias', 'module.waffleiron.channel_mix.43.mlp.2.weight', 'module.waffleiron.channel_mix.43.mlp.2.bias', 'module.waffleiron.channel_mix.44.scale.weight', 'module.waffleiron.channel_mix.44.norm.weight', 'module.waffleiron.channel_mix.44.norm.bias', 'module.waffleiron.channel_mix.44.mlp.0.weight', 'module.waffleiron.channel_mix.44.mlp.0.bias', 'module.waffleiron.channel_mix.44.mlp.2.weight', 'module.waffleiron.channel_mix.44.mlp.2.bias', 'module.waffleiron.channel_mix.45.scale.weight', 'module.waffleiron.channel_mix.45.norm.weight', 'module.waffleiron.channel_mix.45.norm.bias', 'module.waffleiron.channel_mix.45.mlp.0.weight', 'module.waffleiron.channel_mix.45.mlp.0.bias', 'module.waffleiron.channel_mix.45.mlp.2.weight', 'module.waffleiron.channel_mix.45.mlp.2.bias', 'module.waffleiron.channel_mix.46.scale.weight', 'module.waffleiron.channel_mix.46.norm.weight', 'module.waffleiron.channel_mix.46.norm.bias', 'module.waffleiron.channel_mix.46.mlp.0.weight', 'module.waffleiron.channel_mix.46.mlp.0.bias', 'module.waffleiron.channel_mix.46.mlp.2.weight', 'module.waffleiron.channel_mix.46.mlp.2.bias', 'module.waffleiron.channel_mix.47.scale.weight', 'module.waffleiron.channel_mix.47.norm.weight', 'module.waffleiron.channel_mix.47.norm.bias', 'module.waffleiron.channel_mix.47.mlp.0.weight', 'module.waffleiron.channel_mix.47.mlp.0.bias', 'module.waffleiron.channel_mix.47.mlp.2.weight', 'module.waffleiron.channel_mix.47.mlp.2.bias', 'module.waffleiron.spatial_mix.0.scale.weight', 'module.waffleiron.spatial_mix.0.norm.weight', 'module.waffleiron.spatial_mix.0.norm.bias', 'module.waffleiron.spatial_mix.0.ffn.0.weight', 'module.waffleiron.spatial_mix.0.ffn.0.bias', 'module.waffleiron.spatial_mix.0.ffn.2.weight', 'module.waffleiron.spatial_mix.0.ffn.2.bias', 'module.waffleiron.spatial_mix.1.scale.weight', 'module.waffleiron.spatial_mix.1.norm.weight', 'module.waffleiron.spatial_mix.1.norm.bias', 'module.waffleiron.spatial_mix.1.ffn.0.weight', 'module.waffleiron.spatial_mix.1.ffn.0.bias', 'module.waffleiron.spatial_mix.1.ffn.2.weight', 'module.waffleiron.spatial_mix.1.ffn.2.bias', 'module.waffleiron.spatial_mix.2.scale.weight', 'module.waffleiron.spatial_mix.2.norm.weight', 'module.waffleiron.spatial_mix.2.norm.bias', 'module.waffleiron.spatial_mix.2.ffn.0.weight', 'module.waffleiron.spatial_mix.2.ffn.0.bias', 'module.waffleiron.spatial_mix.2.ffn.2.weight', 'module.waffleiron.spatial_mix.2.ffn.2.bias', 'module.waffleiron.spatial_mix.3.scale.weight', 'module.waffleiron.spatial_mix.3.norm.weight', 'module.waffleiron.spatial_mix.3.norm.bias', 'module.waffleiron.spatial_mix.3.ffn.0.weight', 'module.waffleiron.spatial_mix.3.ffn.0.bias', 'module.waffleiron.spatial_mix.3.ffn.2.weight', 'module.waffleiron.spatial_mix.3.ffn.2.bias', 'module.waffleiron.spatial_mix.4.scale.weight', 'module.waffleiron.spatial_mix.4.norm.weight', 'module.waffleiron.spatial_mix.4.norm.bias', 'module.waffleiron.spatial_mix.4.ffn.0.weight', 'module.waffleiron.spatial_mix.4.ffn.0.bias', 'module.waffleiron.spatial_mix.4.ffn.2.weight', 'module.waffleiron.spatial_mix.4.ffn.2.bias', 'module.waffleiron.spatial_mix.5.scale.weight', 'module.waffleiron.spatial_mix.5.norm.weight', 'module.waffleiron.spatial_mix.5.norm.bias', 'module.waffleiron.spatial_mix.5.ffn.0.weight', 'module.waffleiron.spatial_mix.5.ffn.0.bias', 'module.waffleiron.spatial_mix.5.ffn.2.weight', 'module.waffleiron.spatial_mix.5.ffn.2.bias', 'module.waffleiron.spatial_mix.6.scale.weight', 'module.waffleiron.spatial_mix.6.norm.weight', 'module.waffleiron.spatial_mix.6.norm.bias', 'module.waffleiron.spatial_mix.6.ffn.0.weight', 'module.waffleiron.spatial_mix.6.ffn.0.bias', 'module.waffleiron.spatial_mix.6.ffn.2.weight', 'module.waffleiron.spatial_mix.6.ffn.2.bias', 'module.waffleiron.spatial_mix.7.scale.weight', 'module.waffleiron.spatial_mix.7.norm.weight', 'module.waffleiron.spatial_mix.7.norm.bias', 'module.waffleiron.spatial_mix.7.ffn.0.weight', 'module.waffleiron.spatial_mix.7.ffn.0.bias', 'module.waffleiron.spatial_mix.7.ffn.2.weight', 'module.waffleiron.spatial_mix.7.ffn.2.bias', 'module.waffleiron.spatial_mix.8.scale.weight', 'module.waffleiron.spatial_mix.8.norm.weight', 'module.waffleiron.spatial_mix.8.norm.bias', 'module.waffleiron.spatial_mix.8.ffn.0.weight', 'module.waffleiron.spatial_mix.8.ffn.0.bias', 'module.waffleiron.spatial_mix.8.ffn.2.weight', 'module.waffleiron.spatial_mix.8.ffn.2.bias', 'module.waffleiron.spatial_mix.9.scale.weight', 'module.waffleiron.spatial_mix.9.norm.weight', 'module.waffleiron.spatial_mix.9.norm.bias', 'module.waffleiron.spatial_mix.9.ffn.0.weight', 'module.waffleiron.spatial_mix.9.ffn.0.bias', 'module.waffleiron.spatial_mix.9.ffn.2.weight', 'module.waffleiron.spatial_mix.9.ffn.2.bias', 'module.waffleiron.spatial_mix.10.scale.weight', 'module.waffleiron.spatial_mix.10.norm.weight', 'module.waffleiron.spatial_mix.10.norm.bias', 'module.waffleiron.spatial_mix.10.ffn.0.weight', 'module.waffleiron.spatial_mix.10.ffn.0.bias', 'module.waffleiron.spatial_mix.10.ffn.2.weight', 'module.waffleiron.spatial_mix.10.ffn.2.bias', 'module.waffleiron.spatial_mix.11.scale.weight', 'module.waffleiron.spatial_mix.11.norm.weight', 'module.waffleiron.spatial_mix.11.norm.bias', 'module.waffleiron.spatial_mix.11.ffn.0.weight', 'module.waffleiron.spatial_mix.11.ffn.0.bias', 'module.waffleiron.spatial_mix.11.ffn.2.weight', 'module.waffleiron.spatial_mix.11.ffn.2.bias', 'module.waffleiron.spatial_mix.12.scale.weight', 'module.waffleiron.spatial_mix.12.norm.weight', 'module.waffleiron.spatial_mix.12.norm.bias', 'module.waffleiron.spatial_mix.12.ffn.0.weight', 'module.waffleiron.spatial_mix.12.ffn.0.bias', 'module.waffleiron.spatial_mix.12.ffn.2.weight', 'module.waffleiron.spatial_mix.12.ffn.2.bias', 'module.waffleiron.spatial_mix.13.scale.weight', 'module.waffleiron.spatial_mix.13.norm.weight', 'module.waffleiron.spatial_mix.13.norm.bias', 'module.waffleiron.spatial_mix.13.ffn.0.weight', 'module.waffleiron.spatial_mix.13.ffn.0.bias', 'module.waffleiron.spatial_mix.13.ffn.2.weight', 'module.waffleiron.spatial_mix.13.ffn.2.bias', 'module.waffleiron.spatial_mix.14.scale.weight', 'module.waffleiron.spatial_mix.14.norm.weight', 'module.waffleiron.spatial_mix.14.norm.bias', 'module.waffleiron.spatial_mix.14.ffn.0.weight', 'module.waffleiron.spatial_mix.14.ffn.0.bias', 'module.waffleiron.spatial_mix.14.ffn.2.weight', 'module.waffleiron.spatial_mix.14.ffn.2.bias', 'module.waffleiron.spatial_mix.15.scale.weight', 'module.waffleiron.spatial_mix.15.norm.weight', 'module.waffleiron.spatial_mix.15.norm.bias', 'module.waffleiron.spatial_mix.15.ffn.0.weight', 'module.waffleiron.spatial_mix.15.ffn.0.bias', 'module.waffleiron.spatial_mix.15.ffn.2.weight', 'module.waffleiron.spatial_mix.15.ffn.2.bias', 'module.waffleiron.spatial_mix.16.scale.weight', 'module.waffleiron.spatial_mix.16.norm.weight', 'module.waffleiron.spatial_mix.16.norm.bias', 'module.waffleiron.spatial_mix.16.ffn.0.weight', 'module.waffleiron.spatial_mix.16.ffn.0.bias', 'module.waffleiron.spatial_mix.16.ffn.2.weight', 'module.waffleiron.spatial_mix.16.ffn.2.bias', 'module.waffleiron.spatial_mix.17.scale.weight', 'module.waffleiron.spatial_mix.17.norm.weight', 'module.waffleiron.spatial_mix.17.norm.bias', 'module.waffleiron.spatial_mix.17.ffn.0.weight', 'module.waffleiron.spatial_mix.17.ffn.0.bias', 'module.waffleiron.spatial_mix.17.ffn.2.weight', 'module.waffleiron.spatial_mix.17.ffn.2.bias', 'module.waffleiron.spatial_mix.18.scale.weight', 'module.waffleiron.spatial_mix.18.norm.weight', 'module.waffleiron.spatial_mix.18.norm.bias', 'module.waffleiron.spatial_mix.18.ffn.0.weight', 'module.waffleiron.spatial_mix.18.ffn.0.bias', 'module.waffleiron.spatial_mix.18.ffn.2.weight', 'module.waffleiron.spatial_mix.18.ffn.2.bias', 'module.waffleiron.spatial_mix.19.scale.weight', 'module.waffleiron.spatial_mix.19.norm.weight', 'module.waffleiron.spatial_mix.19.norm.bias', 'module.waffleiron.spatial_mix.19.ffn.0.weight', 'module.waffleiron.spatial_mix.19.ffn.0.bias', 'module.waffleiron.spatial_mix.19.ffn.2.weight', 'module.waffleiron.spatial_mix.19.ffn.2.bias', 'module.waffleiron.spatial_mix.20.scale.weight', 'module.waffleiron.spatial_mix.20.norm.weight', 'module.waffleiron.spatial_mix.20.norm.bias', 'module.waffleiron.spatial_mix.20.ffn.0.weight', 'module.waffleiron.spatial_mix.20.ffn.0.bias', 'module.waffleiron.spatial_mix.20.ffn.2.weight', 'module.waffleiron.spatial_mix.20.ffn.2.bias', 'module.waffleiron.spatial_mix.21.scale.weight', 'module.waffleiron.spatial_mix.21.norm.weight', 'module.waffleiron.spatial_mix.21.norm.bias', 'module.waffleiron.spatial_mix.21.ffn.0.weight', 'module.waffleiron.spatial_mix.21.ffn.0.bias', 'module.waffleiron.spatial_mix.21.ffn.2.weight', 'module.waffleiron.spatial_mix.21.ffn.2.bias', 'module.waffleiron.spatial_mix.22.scale.weight', 'module.waffleiron.spatial_mix.22.norm.weight', 'module.waffleiron.spatial_mix.22.norm.bias', 'module.waffleiron.spatial_mix.22.ffn.0.weight', 'module.waffleiron.spatial_mix.22.ffn.0.bias', 'module.waffleiron.spatial_mix.22.ffn.2.weight', 'module.waffleiron.spatial_mix.22.ffn.2.bias', 'module.waffleiron.spatial_mix.23.scale.weight', 'module.waffleiron.spatial_mix.23.norm.weight', 'module.waffleiron.spatial_mix.23.norm.bias', 'module.waffleiron.spatial_mix.23.ffn.0.weight', 'module.waffleiron.spatial_mix.23.ffn.0.bias', 'module.waffleiron.spatial_mix.23.ffn.2.weight', 'module.waffleiron.spatial_mix.23.ffn.2.bias', 'module.waffleiron.spatial_mix.24.scale.weight', 'module.waffleiron.spatial_mix.24.norm.weight', 'module.waffleiron.spatial_mix.24.norm.bias', 'module.waffleiron.spatial_mix.24.ffn.0.weight', 'module.waffleiron.spatial_mix.24.ffn.0.bias', 'module.waffleiron.spatial_mix.24.ffn.2.weight', 'module.waffleiron.spatial_mix.24.ffn.2.bias', 'module.waffleiron.spatial_mix.25.scale.weight', 'module.waffleiron.spatial_mix.25.norm.weight', 'module.waffleiron.spatial_mix.25.norm.bias', 'module.waffleiron.spatial_mix.25.ffn.0.weight', 'module.waffleiron.spatial_mix.25.ffn.0.bias', 'module.waffleiron.spatial_mix.25.ffn.2.weight', 'module.waffleiron.spatial_mix.25.ffn.2.bias', 'module.waffleiron.spatial_mix.26.scale.weight', 'module.waffleiron.spatial_mix.26.norm.weight', 'module.waffleiron.spatial_mix.26.norm.bias', 'module.waffleiron.spatial_mix.26.ffn.0.weight', 'module.waffleiron.spatial_mix.26.ffn.0.bias', 'module.waffleiron.spatial_mix.26.ffn.2.weight', 'module.waffleiron.spatial_mix.26.ffn.2.bias', 'module.waffleiron.spatial_mix.27.scale.weight', 'module.waffleiron.spatial_mix.27.norm.weight', 'module.waffleiron.spatial_mix.27.norm.bias', 'module.waffleiron.spatial_mix.27.ffn.0.weight', 'module.waffleiron.spatial_mix.27.ffn.0.bias', 'module.waffleiron.spatial_mix.27.ffn.2.weight', 'module.waffleiron.spatial_mix.27.ffn.2.bias', 'module.waffleiron.spatial_mix.28.scale.weight', 'module.waffleiron.spatial_mix.28.norm.weight', 'module.waffleiron.spatial_mix.28.norm.bias', 'module.waffleiron.spatial_mix.28.ffn.0.weight', 'module.waffleiron.spatial_mix.28.ffn.0.bias', 'module.waffleiron.spatial_mix.28.ffn.2.weight', 'module.waffleiron.spatial_mix.28.ffn.2.bias', 'module.waffleiron.spatial_mix.29.scale.weight', 'module.waffleiron.spatial_mix.29.norm.weight', 'module.waffleiron.spatial_mix.29.norm.bias', 'module.waffleiron.spatial_mix.29.ffn.0.weight', 'module.waffleiron.spatial_mix.29.ffn.0.bias', 'module.waffleiron.spatial_mix.29.ffn.2.weight', 'module.waffleiron.spatial_mix.29.ffn.2.bias', 'module.waffleiron.spatial_mix.30.scale.weight', 'module.waffleiron.spatial_mix.30.norm.weight', 'module.waffleiron.spatial_mix.30.norm.bias', 'module.waffleiron.spatial_mix.30.ffn.0.weight', 'module.waffleiron.spatial_mix.30.ffn.0.bias', 'module.waffleiron.spatial_mix.30.ffn.2.weight', 'module.waffleiron.spatial_mix.30.ffn.2.bias', 'module.waffleiron.spatial_mix.31.scale.weight', 'module.waffleiron.spatial_mix.31.norm.weight', 'module.waffleiron.spatial_mix.31.norm.bias', 'module.waffleiron.spatial_mix.31.ffn.0.weight', 'module.waffleiron.spatial_mix.31.ffn.0.bias', 'module.waffleiron.spatial_mix.31.ffn.2.weight', 'module.waffleiron.spatial_mix.31.ffn.2.bias', 'module.waffleiron.spatial_mix.32.scale.weight', 'module.waffleiron.spatial_mix.32.norm.weight', 'module.waffleiron.spatial_mix.32.norm.bias', 'module.waffleiron.spatial_mix.32.ffn.0.weight', 'module.waffleiron.spatial_mix.32.ffn.0.bias', 'module.waffleiron.spatial_mix.32.ffn.2.weight', 'module.waffleiron.spatial_mix.32.ffn.2.bias', 'module.waffleiron.spatial_mix.33.scale.weight', 'module.waffleiron.spatial_mix.33.norm.weight', 'module.waffleiron.spatial_mix.33.norm.bias', 'module.waffleiron.spatial_mix.33.ffn.0.weight', 'module.waffleiron.spatial_mix.33.ffn.0.bias', 'module.waffleiron.spatial_mix.33.ffn.2.weight', 'module.waffleiron.spatial_mix.33.ffn.2.bias', 'module.waffleiron.spatial_mix.34.scale.weight', 'module.waffleiron.spatial_mix.34.norm.weight', 'module.waffleiron.spatial_mix.34.norm.bias', 'module.waffleiron.spatial_mix.34.ffn.0.weight', 'module.waffleiron.spatial_mix.34.ffn.0.bias', 'module.waffleiron.spatial_mix.34.ffn.2.weight', 'module.waffleiron.spatial_mix.34.ffn.2.bias', 'module.waffleiron.spatial_mix.35.scale.weight', 'module.waffleiron.spatial_mix.35.norm.weight', 'module.waffleiron.spatial_mix.35.norm.bias', 'module.waffleiron.spatial_mix.35.ffn.0.weight', 'module.waffleiron.spatial_mix.35.ffn.0.bias', 'module.waffleiron.spatial_mix.35.ffn.2.weight', 'module.waffleiron.spatial_mix.35.ffn.2.bias', 'module.waffleiron.spatial_mix.36.scale.weight', 'module.waffleiron.spatial_mix.36.norm.weight', 'module.waffleiron.spatial_mix.36.norm.bias', 'module.waffleiron.spatial_mix.36.ffn.0.weight', 'module.waffleiron.spatial_mix.36.ffn.0.bias', 'module.waffleiron.spatial_mix.36.ffn.2.weight', 'module.waffleiron.spatial_mix.36.ffn.2.bias', 'module.waffleiron.spatial_mix.37.scale.weight', 'module.waffleiron.spatial_mix.37.norm.weight', 'module.waffleiron.spatial_mix.37.norm.bias', 'module.waffleiron.spatial_mix.37.ffn.0.weight', 'module.waffleiron.spatial_mix.37.ffn.0.bias', 'module.waffleiron.spatial_mix.37.ffn.2.weight', 'module.waffleiron.spatial_mix.37.ffn.2.bias', 'module.waffleiron.spatial_mix.38.scale.weight', 'module.waffleiron.spatial_mix.38.norm.weight', 'module.waffleiron.spatial_mix.38.norm.bias', 'module.waffleiron.spatial_mix.38.ffn.0.weight', 'module.waffleiron.spatial_mix.38.ffn.0.bias', 'module.waffleiron.spatial_mix.38.ffn.2.weight', 'module.waffleiron.spatial_mix.38.ffn.2.bias', 'module.waffleiron.spatial_mix.39.scale.weight', 'module.waffleiron.spatial_mix.39.norm.weight', 'module.waffleiron.spatial_mix.39.norm.bias', 'module.waffleiron.spatial_mix.39.ffn.0.weight', 'module.waffleiron.spatial_mix.39.ffn.0.bias', 'module.waffleiron.spatial_mix.39.ffn.2.weight', 'module.waffleiron.spatial_mix.39.ffn.2.bias', 'module.waffleiron.spatial_mix.40.scale.weight', 'module.waffleiron.spatial_mix.40.norm.weight', 'module.waffleiron.spatial_mix.40.norm.bias', 'module.waffleiron.spatial_mix.40.ffn.0.weight', 'module.waffleiron.spatial_mix.40.ffn.0.bias', 'module.waffleiron.spatial_mix.40.ffn.2.weight', 'module.waffleiron.spatial_mix.40.ffn.2.bias', 'module.waffleiron.spatial_mix.41.scale.weight', 'module.waffleiron.spatial_mix.41.norm.weight', 'module.waffleiron.spatial_mix.41.norm.bias', 'module.waffleiron.spatial_mix.41.ffn.0.weight', 'module.waffleiron.spatial_mix.41.ffn.0.bias', 'module.waffleiron.spatial_mix.41.ffn.2.weight', 'module.waffleiron.spatial_mix.41.ffn.2.bias', 'module.waffleiron.spatial_mix.42.scale.weight', 'module.waffleiron.spatial_mix.42.norm.weight', 'module.waffleiron.spatial_mix.42.norm.bias', 'module.waffleiron.spatial_mix.42.ffn.0.weight', 'module.waffleiron.spatial_mix.42.ffn.0.bias', 'module.waffleiron.spatial_mix.42.ffn.2.weight', 'module.waffleiron.spatial_mix.42.ffn.2.bias', 'module.waffleiron.spatial_mix.43.scale.weight', 'module.waffleiron.spatial_mix.43.norm.weight', 'module.waffleiron.spatial_mix.43.norm.bias', 'module.waffleiron.spatial_mix.43.ffn.0.weight', 'module.waffleiron.spatial_mix.43.ffn.0.bias', 'module.waffleiron.spatial_mix.43.ffn.2.weight', 'module.waffleiron.spatial_mix.43.ffn.2.bias', 'module.waffleiron.spatial_mix.44.scale.weight', 'module.waffleiron.spatial_mix.44.norm.weight', 'module.waffleiron.spatial_mix.44.norm.bias', 'module.waffleiron.spatial_mix.44.ffn.0.weight', 'module.waffleiron.spatial_mix.44.ffn.0.bias', 'module.waffleiron.spatial_mix.44.ffn.2.weight', 'module.waffleiron.spatial_mix.44.ffn.2.bias', 'module.waffleiron.spatial_mix.45.scale.weight', 'module.waffleiron.spatial_mix.45.norm.weight', 'module.waffleiron.spatial_mix.45.norm.bias', 'module.waffleiron.spatial_mix.45.ffn.0.weight', 'module.waffleiron.spatial_mix.45.ffn.0.bias', 'module.waffleiron.spatial_mix.45.ffn.2.weight', 'module.waffleiron.spatial_mix.45.ffn.2.bias', 'module.waffleiron.spatial_mix.46.scale.weight', 'module.waffleiron.spatial_mix.46.norm.weight', 'module.waffleiron.spatial_mix.46.norm.bias', 'module.waffleiron.spatial_mix.46.ffn.0.weight', 'module.waffleiron.spatial_mix.46.ffn.0.bias', 'module.waffleiron.spatial_mix.46.ffn.2.weight', 'module.waffleiron.spatial_mix.46.ffn.2.bias', 'module.waffleiron.spatial_mix.47.scale.weight', 'module.waffleiron.spatial_mix.47.norm.weight', 'module.waffleiron.spatial_mix.47.norm.bias', 'module.waffleiron.spatial_mix.47.ffn.0.weight', 'module.waffleiron.spatial_mix.47.ffn.0.bias', 'module.waffleiron.spatial_mix.47.ffn.2.weight', 'module.waffleiron.spatial_mix.47.ffn.2.bias', 'module.classif.0.weight', 'module.classif.0.bias', 'module.classif.0.running_mean', 'module.classif.0.running_var', 'module.classif.0.num_batches_tracked', 'module.classif.1.weight', 'module.classif.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c587871",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt = {}\n",
    "for k in ckpt.keys():\n",
    "    if k.startswith(\"module\"):\n",
    "        if k.startswith(\"module.classif.0\"):\n",
    "            continue\n",
    "        elif k.startswith(\"module.classif.1\"):\n",
    "            new_ckpt[\"classif\" + k[len(\"module.classif.1\") :]] = ckpt[k]\n",
    "        else:\n",
    "            new_ckpt[k[len(\"module.\") :]] = ckpt[k]\n",
    "    else:\n",
    "        new_ckpt[k] = ckpt[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a10e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ckpt.get(\"classif.weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca00085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84e7d8",
   "metadata": {},
   "source": [
    "## Model loaded --> Test features somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from auxiliary.process_data.nuscenes.nuscenes_dataset import DatasetTrainVal\n",
    "\n",
    "print(\"Creating dataloader...\", flush=True)\n",
    "\n",
    "target = '/root/main/dataset/processed'\n",
    "\n",
    "filelist_train = [os.path.join(target, 'train_pointclouds', fname) for fname in os.listdir(os.path.join(target, 'train_pointclouds')) if os.path.splitext(fname)[1]==\".npy\"]\n",
    "filelist_train.sort()\n",
    "filelist_val = filelist_train[:3]\n",
    "filelist_train = filelist_train[3:]\n",
    "\n",
    "ds = DatasetTrainVal(filelist_train, os.path.join(target, 'train_pointclouds'),\n",
    "                            training=True,\n",
    "                            npoints=2000,\n",
    "                            iteration_number=(2*10)*10,\n",
    "                            jitter=0.2)\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, # Change batch_size\n",
    "                                    num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2884a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_loader:\n",
    "    print(torch.bincount(t['target'][0]))\n",
    "    x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8d1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_filenames = [\"Lille1_1.ply\",  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",]\n",
    "destdir = '/root/main/dataset/processed/'\n",
    "rootdir = '/root/main/dataset/'\n",
    "\n",
    "filenames = train_filenames\n",
    "save_dir = os.path.join(destdir,\"train_pointclouds\")\n",
    "pts_all = {}\n",
    "for filename in filenames:\n",
    "    fname = os.path.join(rootdir, \"training_10_classes\", filename)\n",
    "    plydata = PlyData.read(fname)\n",
    "    x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "    y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "    z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "    reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "    label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "    pts = np.concatenate([\n",
    "        np.expand_dims(x,1),\n",
    "        np.expand_dims(y,1),\n",
    "        np.expand_dims(z,1),\n",
    "        np.expand_dims(reflectance,1),\n",
    "        np.expand_dims(label,1),\n",
    "    ], axis=1).astype(np.float32)\n",
    "    pts_all[filename] = pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfc59a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  83.03686 ,   83.05253 ,   83.117584, ..., -386.54715 ,\n",
       "       -386.5629  , -386.97958 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_all[\"Lille1_1.ply\"][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-360.1785\n",
      "67.185555\n",
      "-412.13937\n",
      "101.893524\n",
      "32.78496\n",
      "66.74454\n"
     ]
    }
   ],
   "source": [
    "print(min(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,2]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4331e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.701644699999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(101.893524 - (-412.13937))/20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e96dcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 25 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01441ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.705505\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6416d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.756725\n"
     ]
    }
   ],
   "source": [
    "print(np.std(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pc_here = torch.from_numpy(pts_all[\"Lille1_1.ply\"]).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize_pointcloud(points, voxel_size):\n",
    "    \"\"\"\n",
    "    Voxelizes a point cloud.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): The point cloud as an Nx3 array of XYZ coordinates.\n",
    "        voxel_size (float): The size of the voxels (uniform along all axes).\n",
    "        \n",
    "    Returns:\n",
    "        voxel_indices (np.ndarray): The voxel indices for each point.\n",
    "        voxel_grid (dict): A dictionary where keys are voxel indices (tuples) and values are points in that voxel.\n",
    "    \"\"\"\n",
    "    # Normalize points by voxel size\n",
    "    voxel_indices = np.floor(points[:,:3] / voxel_size).astype(np.int32)\n",
    "    \n",
    "    # Create a dictionary to store points in each voxel\n",
    "    voxel_grid = {}\n",
    "    \n",
    "    for idx, voxel in tqdm(enumerate(voxel_indices)):\n",
    "        voxel_key = tuple(voxel)  # Use tuple to make it hashable for the dictionary\n",
    "        if voxel_key not in voxel_grid:\n",
    "            voxel_grid[voxel_key] = []\n",
    "        voxel_grid[voxel_key].append(points[idx])\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    for key in voxel_grid:\n",
    "        voxel_grid[key] = np.array(voxel_grid[key])\n",
    "    \n",
    "    return voxel_indices, voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9efe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#point_cloud = np.random.rand(1000, 3) * 100  # 1000 points in a 100x100x100 space\n",
    "voxel_size = 20.0  # Voxel size of 5 units\n",
    "\n",
    "# Voxelize the point cloud\n",
    "voxel_indices, voxel_grid = voxelize_pointcloud(pts_all[\"Lille1_1.ply\"], voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results\n",
    "print(\"Voxel indices:\\n\", voxel_indices[900])  # Show first 10 voxel indices\n",
    "print(\"\\nNumber of unique voxels:\", len(voxel_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    if len(voxel_grid[i]) < 100:\n",
    "        voxel_grid.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    voxel_grid[i][:,4] = voxel_grid[i][:,4] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(voxel_grid[i][:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f2c3d",
   "metadata": {},
   "source": [
    "## Model Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c4ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(\"cuda:0\")\n",
    "model = model.cuda(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e309a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Conv1d(768, 16, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d10d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils.transforms as tr\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import os\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "class PCDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rootdir=None,\n",
    "        phase=\"train\",\n",
    "        input_feat=\"intensity\",\n",
    "        voxel_size=0.1,\n",
    "        train_augmentations=None,\n",
    "        dim_proj=[\n",
    "            0,\n",
    "        ],\n",
    "        grids_shape=[(256, 256)],\n",
    "        fov_xyz=(\n",
    "            (-1.0, -1.0, -1.0),\n",
    "            (1.0, 1.0, 1.0),\n",
    "        ),\n",
    "        num_neighbors=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dataset split\n",
    "        self.phase = phase\n",
    "        assert self.phase in [\"train\", \"val\", \"trainval\", \"test\"]\n",
    "\n",
    "        # Root directory of dataset\n",
    "        self.rootdir = rootdir\n",
    "\n",
    "        # Input features to compute for each point\n",
    "        self.input_feat = input_feat\n",
    "\n",
    "        # Downsample input point cloud by small voxelization\n",
    "        self.downsample = tr.Voxelize(\n",
    "            dims=(0, 1, 2),\n",
    "            voxel_size=voxel_size,\n",
    "            random=(self.phase == \"train\" or self.phase == \"trainval\"),\n",
    "        )\n",
    "\n",
    "        # Field of view\n",
    "        assert len(fov_xyz[0]) == len(\n",
    "            fov_xyz[1]\n",
    "        ), \"Min and Max FOV must have the same length.\"\n",
    "        for i, (min, max) in enumerate(zip(*fov_xyz)):\n",
    "            assert (\n",
    "                min < max\n",
    "            ), f\"Field of view: min ({min}) < max ({max}) is expected on dimension {i}.\"\n",
    "        self.fov_xyz = np.concatenate([np.array(f)[None] for f in fov_xyz], axis=0)\n",
    "        self.crop_to_fov = tr.Crop(dims=(0, 1, 2), fov=fov_xyz)\n",
    "\n",
    "        # Grid shape for projection in 2D\n",
    "        assert len(grids_shape) == len(dim_proj)\n",
    "        self.dim_proj = dim_proj\n",
    "        self.grids_shape = [np.array(g) for g in grids_shape]\n",
    "        self.lut_axis_plane = {0: (1, 2), 1: (0, 2), 2: (0, 1)}\n",
    "\n",
    "        # Number of neighbors for embedding layer\n",
    "        assert num_neighbors > 0\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        # Train time augmentations\n",
    "        if train_augmentations is not None:\n",
    "            assert self.phase in [\"train\", \"trainval\"]\n",
    "        self.train_augmentations = train_augmentations\n",
    "        \n",
    "        self.list_frames = [\"Lille1_1.ply\"] # ,  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",\n",
    "        self.mean_int = 18.705505\n",
    "        self.std_int = 23.756725\n",
    "\n",
    "    def get_occupied_2d_cells(self, pc):\n",
    "        \"\"\"Return mapping between 3D point and corresponding 2D cell\"\"\"\n",
    "        cell_ind = []\n",
    "        for dim, grid in zip(self.dim_proj, self.grids_shape):\n",
    "            # Get plane of which to project\n",
    "            dims = self.lut_axis_plane[dim]\n",
    "            # Compute grid resolution\n",
    "            res = (self.fov_xyz[1, dims] - self.fov_xyz[0, dims]) / grid[None]\n",
    "            # Shift and quantize point cloud\n",
    "            pc_quant = ((pc[:, dims] - self.fov_xyz[0, dims]) / res).astype(\"int\")\n",
    "            # Check that the point cloud fits on the grid\n",
    "            min, max = pc_quant.min(0), pc_quant.max(0)\n",
    "            assert min[0] >= 0 and min[1] >= 0, print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            assert max[0] < grid[0] and max[1] < grid[1], print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            # Transform quantized coordinates to cell indices for projection on 2D plane\n",
    "            temp = pc_quant[:, 0] * grid[1] + pc_quant[:, 1]\n",
    "            cell_ind.append(temp[None])\n",
    "        return np.vstack(cell_ind)\n",
    "\n",
    "    def prepare_input_features(self, pc_orig):\n",
    "        # Concatenate desired input features to coordinates\n",
    "        pc = [pc_orig[:, :3]]  # Initialize with coordinates\n",
    "        for type in self.input_feat:\n",
    "            if type == \"intensity\":\n",
    "                intensity = pc_orig[:, 3:]\n",
    "                intensity = (intensity - self.mean_int) / self.std_int\n",
    "                pc.append(intensity)\n",
    "            elif type == \"height\":\n",
    "                pc.append(pc_orig[:, 2:3])\n",
    "            elif type == \"radius\":\n",
    "                r_xyz = np.linalg.norm(pc_orig[:, :3], axis=1, keepdims=True)\n",
    "                pc.append(r_xyz)\n",
    "            elif type == \"xyz\":\n",
    "                xyz = pc_orig[:, :3]\n",
    "                pc.append(xyz)\n",
    "            elif type == \"constant\":\n",
    "                pc.append(np.ones((pc_orig.shape[0], 1)))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature: {type}\")\n",
    "        return np.concatenate(pc, 1)\n",
    "\n",
    "    def load_pc(self, index):\n",
    "        fname = os.path.join(self.rootdir, \"training_10_classes\", self.list_frames[index])\n",
    "        print(\"Loading\")\n",
    "        plydata = PlyData.read(fname)\n",
    "        x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "        y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "        z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "        reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "        #print(x.shape[0])\n",
    "        feats = np.zeros((x.shape[0], 1))\n",
    "        label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "        label = label-1\n",
    "        pts = np.concatenate([\n",
    "            np.expand_dims(x,1),\n",
    "            np.expand_dims(y,1),\n",
    "            np.expand_dims(z,1),\n",
    "            np.expand_dims(reflectance,1),\n",
    "            feats,\n",
    "        ], axis=1).astype(np.float32)\n",
    "        print(\"Finished\")\n",
    "        \n",
    "        return pts, np.expand_dims(label,1), self.list_frames[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_frames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load original point cloud\n",
    "        pc_orig, labels_orig, filename = self.load_pc(index)\n",
    "\n",
    "        # Prepare input feature\n",
    "        pc_orig = self.prepare_input_features(pc_orig)\n",
    "\n",
    "        # Voxelization\n",
    "        pc, labels = self.downsample(pc_orig, labels_orig)\n",
    "\n",
    "        # Augment data\n",
    "        if self.train_augmentations is not None:\n",
    "            pc, labels = self.train_augmentations(pc, labels)\n",
    "\n",
    "        # Crop to fov\n",
    "        pc, labels = self.crop_to_fov(pc, labels)\n",
    "\n",
    "        # For each point, get index of corresponding 2D cells on projected grid\n",
    "        cell_ind = self.get_occupied_2d_cells(pc)\n",
    "\n",
    "        # Get neighbors for point embedding layer providing tokens to waffleiron backbone\n",
    "        kdtree = KDTree(pc[:, :3])\n",
    "        assert pc.shape[0] > self.num_neighbors\n",
    "        dist, neighbors_emb = kdtree.query(pc[:, :3], k=self.num_neighbors + 1)\n",
    "\n",
    "        # Nearest neighbor interpolation to undo cropping & voxelisation at validation time\n",
    "        if self.phase in [\"train\", \"trainval\"]:\n",
    "            upsample = np.arange(pc.shape[0])\n",
    "        else:\n",
    "            _, upsample = kdtree.query(pc_orig[:, :3], k=1)\n",
    "\n",
    "        # Output to return\n",
    "        out = (\n",
    "            # Point features\n",
    "            pc[:, 3:].T[None],\n",
    "            # Point labels of original entire point cloud\n",
    "            labels if self.phase in [\"train\", \"trainval\"] else labels_orig,\n",
    "            # Projection 2D -> 3D: index of 2D cells for each point\n",
    "            cell_ind[None],\n",
    "            # Neighborhood for point embedding layer, which provides tokens to waffleiron backbone\n",
    "            neighbors_emb.T[None],\n",
    "            # For interpolation from voxelized & cropped point cloud to original point cloud\n",
    "            upsample,\n",
    "            # Filename of original point cloud\n",
    "            filename,\n",
    "        )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337afe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, num_points=None):\n",
    "        self.num_points = num_points\n",
    "        assert num_points is None or num_points > 0\n",
    "\n",
    "    def __call__(self, list_data):\n",
    "\n",
    "        # Extract all data\n",
    "        list_of_data = (list(data) for data in zip(*list_data))\n",
    "        feat, label_orig, cell_ind, neighbors_emb, upsample, filename = list_of_data\n",
    "\n",
    "        # Zero-pad point clouds\n",
    "        Nmax = np.max([f.shape[-1] for f in feat])\n",
    "        if self.num_points is not None:\n",
    "            assert Nmax <= self.num_points\n",
    "        occupied_cells = []\n",
    "        for i in range(len(feat)):\n",
    "            feat[i], neighbors_emb[i], cell_ind[i], temp = zero_pad(\n",
    "                feat[i],\n",
    "                neighbors_emb[i],\n",
    "                cell_ind[i],\n",
    "                Nmax if self.num_points is None else self.num_points,\n",
    "            )\n",
    "            occupied_cells.append(temp)\n",
    "\n",
    "        # Concatenate along batch dimension\n",
    "        feat = torch.from_numpy(np.vstack(feat)).float()  # B x C x Nmax\n",
    "        neighbors_emb = torch.from_numpy(np.vstack(neighbors_emb)).long()  # B x Nmax\n",
    "        cell_ind = torch.from_numpy(\n",
    "            np.vstack(cell_ind)\n",
    "        ).long()  # B x nb_2d_cells x Nmax\n",
    "        occupied_cells = torch.from_numpy(np.vstack(occupied_cells)).float()  # B x Nmax\n",
    "        labels_orig = torch.from_numpy(np.hstack(label_orig)).long()\n",
    "        upsample = [torch.from_numpy(u) for u in upsample]\n",
    "\n",
    "        # Prepare output variables\n",
    "        out = {\n",
    "            \"feat\": feat,\n",
    "            \"neighbors_emb\": neighbors_emb,\n",
    "            \"upsample\": upsample,\n",
    "            \"labels_orig\": labels_orig,\n",
    "            \"cell_ind\": cell_ind,\n",
    "            \"occupied_cells\": occupied_cells,\n",
    "            \"filename\": filename,\n",
    "        }\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1814ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(feat, neighbors_emb, cell_ind, Nmax):\n",
    "    N = feat.shape[-1]\n",
    "    assert N <= Nmax\n",
    "    occupied_cells = np.ones((1, Nmax))\n",
    "    if N < Nmax:\n",
    "        # Zero-pad with null features\n",
    "        feat = np.concatenate((feat, np.zeros((1, feat.shape[1], Nmax - N))), axis=2)\n",
    "        # For zero-padded points, associate last zero-padded points as neighbor\n",
    "        neighbors_emb = np.concatenate(\n",
    "            (\n",
    "                neighbors_emb,\n",
    "                (Nmax - 1) * np.ones((1, neighbors_emb.shape[1], Nmax - N)),\n",
    "            ),\n",
    "            axis=2,\n",
    "        )\n",
    "        # Associate zero-padded points to first 2D cell...\n",
    "        cell_ind = np.concatenate(\n",
    "            (cell_ind, np.zeros((1, cell_ind.shape[1], Nmax - N))), axis=2\n",
    "        )\n",
    "        # ... and at the same time mark zero-padded points as unoccupied\n",
    "        occupied_cells[:, N:] = 0\n",
    "    return feat, neighbors_emb, cell_ind, occupied_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3bad12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"rootdir\": '/root/main/dataset/',\n",
    "        \"input_feat\": [\"xyz\", \"intensity\"],\n",
    "        \"voxel_size\": 5,\n",
    "        \"num_neighbors\": 16,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, 40], [64, 64, 60]], # Check here\n",
    "    }\n",
    "\n",
    "train_dataset = PCDataset(\n",
    "        phase=\"val\",\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1dae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ce92bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HyperLiDAR/models/waffleiron/helper_projection.py:32: UserWarning: scatter_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1615.)\n",
      "  include_self=False,\n"
     ]
    }
   ],
   "source": [
    "for it, batch in enumerate(train_loader):\n",
    "    \n",
    "    if it == 0:\n",
    "\n",
    "        # Network inputs\n",
    "        #print(batch[\"upsample\"])\n",
    "        feat = batch[\"feat\"].cuda(0, non_blocking=True)\n",
    "        labels = batch[\"labels_orig\"].cuda(0, non_blocking=True)\n",
    "        batch[\"upsample\"] = [\n",
    "            up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "        ]\n",
    "        cell_ind = batch[\"cell_ind\"].cuda(0, non_blocking=True)\n",
    "        occupied_cell = batch[\"occupied_cells\"].cuda(0, non_blocking=True)\n",
    "        neighbors_emb = batch[\"neighbors_emb\"].cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(*net_inputs)\n",
    "        \n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f2e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 708])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6999c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffb61411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([679, 679, 679,  ...,   3,   3,   3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Voxels to points\n",
    "out_upsample = []\n",
    "for id_b, closest_point in enumerate(batch[\"upsample\"]):\n",
    "    print(id_b)\n",
    "    print(closest_point)\n",
    "    temp = out[id_b, :, closest_point]\n",
    "    out_upsample.append(temp.T)\n",
    "out_2 = torch.cat(out_upsample, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ee03ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 491.1151, -406.0366,   19.5726,  ...,   61.3165,  205.1153,\n",
       "          -69.1532],\n",
       "        [ 491.1151, -406.0366,   19.5726,  ...,   61.3165,  205.1153,\n",
       "          -69.1532],\n",
       "        [ 491.1151, -406.0366,   19.5726,  ...,   61.3165,  205.1153,\n",
       "          -69.1532],\n",
       "        ...,\n",
       "        [-177.6138,  370.1334, -247.4674,  ...,  -15.6165,  580.3881,\n",
       "         -157.9118],\n",
       "        [-177.6138,  370.1334, -247.4674,  ...,  -15.6165,  580.3881,\n",
       "         -157.9118],\n",
       "        [-177.6138,  370.1334, -247.4674,  ...,  -15.6165,  580.3881,\n",
       "         -157.9118]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc098256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32f7a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    nb_class = out_2.shape[1]\n",
    "    pred_label = out_2.max(1)[1]\n",
    "    labels = labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80368336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30033430])\n",
      "torch.Size([30033430])\n"
     ]
    }
   ],
   "source": [
    "print(pred_label.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa3588",
   "metadata": {},
   "source": [
    "### Npm3D\n",
    "\n",
    "0 unclassified\n",
    "1 ground\n",
    "2 building\n",
    "3 pole - road sign - traffic light\n",
    "4 bollard - small pole\n",
    "5 trash can\n",
    "6 barrier\n",
    "7 pedestrian\n",
    "8 car\n",
    "9 natural - vegetation\n",
    "\n",
    "### Nuscenes\n",
    "\n",
    "0: 'noise'\n",
    "1: 'barrier'\n",
    "2: 'bicycle'\n",
    "3: 'bus'\n",
    "4: 'car'\n",
    "5: 'construction_vehicle'\n",
    "6: 'motorcycle'\n",
    "7: 'pedestrian'\n",
    "8: 'traffic_cone'\n",
    "9: 'trailer'\n",
    "10: 'truck'\n",
    "11: 'driveable_surface'\n",
    "12: 'other_flat'\n",
    "13: 'sidewalk'\n",
    "14: 'terrain'\n",
    "15: 'manmade'\n",
    "16: 'vegetation'\n",
    "\n",
    "0 - 0\n",
    "1 - 11 or 12 or 13 or 14\n",
    "2 - IGNORE\n",
    "3 - 8\n",
    "4 - IGNORE\n",
    "5 - IGNORE\n",
    "6 - 1\n",
    "7 - 7\n",
    "8 - 2 or 3 or 4 or 5 or 6 or 9 or 10\n",
    "9 - 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ba850",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = {1:6, 2:8, 3:8, 4:8, 5:8, 6:8, 7:7, 8:3, 9:9, 10:8, 11:1, 12:1, 13:1, 14:1, 15:2, 16:9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pred_labels_change = []\n",
    "for i in tqdm(pred_label):\n",
    "    pred_labels_change.append(change[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DLabelProp",
   "language": "python",
   "name": "3dlabelprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
