{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd417ca",
   "metadata": {},
   "source": [
    "# Test WaffleIron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afc500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12df3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter(\n",
    "    input_channels=5,\n",
    "    feat_channels=768,\n",
    "    depth=48,\n",
    "    grid_shape=[[256, 256], [256, 32], [256, 32]],\n",
    "    nb_class=16, # class for prediction\n",
    "    #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "    layer_norm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff7e82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "ckpt = torch.load('./saved_models/ckpt_last_scalr.pth', map_location=\"cuda:0\")\n",
    "ckpt = ckpt[\"net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4933ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['module.embed.norm.weight', 'module.embed.norm.bias', 'module.embed.norm.running_mean', 'module.embed.norm.running_var', 'module.embed.norm.num_batches_tracked', 'module.embed.conv1.weight', 'module.embed.conv1.bias', 'module.embed.conv2.0.weight', 'module.embed.conv2.0.bias', 'module.embed.conv2.0.running_mean', 'module.embed.conv2.0.running_var', 'module.embed.conv2.0.num_batches_tracked', 'module.embed.conv2.1.weight', 'module.embed.conv2.2.weight', 'module.embed.conv2.2.bias', 'module.embed.conv2.2.running_mean', 'module.embed.conv2.2.running_var', 'module.embed.conv2.2.num_batches_tracked', 'module.embed.conv2.4.weight', 'module.embed.final.weight', 'module.embed.final.bias', 'module.waffleiron.channel_mix.0.scale.weight', 'module.waffleiron.channel_mix.0.norm.weight', 'module.waffleiron.channel_mix.0.norm.bias', 'module.waffleiron.channel_mix.0.mlp.0.weight', 'module.waffleiron.channel_mix.0.mlp.0.bias', 'module.waffleiron.channel_mix.0.mlp.2.weight', 'module.waffleiron.channel_mix.0.mlp.2.bias', 'module.waffleiron.channel_mix.1.scale.weight', 'module.waffleiron.channel_mix.1.norm.weight', 'module.waffleiron.channel_mix.1.norm.bias', 'module.waffleiron.channel_mix.1.mlp.0.weight', 'module.waffleiron.channel_mix.1.mlp.0.bias', 'module.waffleiron.channel_mix.1.mlp.2.weight', 'module.waffleiron.channel_mix.1.mlp.2.bias', 'module.waffleiron.channel_mix.2.scale.weight', 'module.waffleiron.channel_mix.2.norm.weight', 'module.waffleiron.channel_mix.2.norm.bias', 'module.waffleiron.channel_mix.2.mlp.0.weight', 'module.waffleiron.channel_mix.2.mlp.0.bias', 'module.waffleiron.channel_mix.2.mlp.2.weight', 'module.waffleiron.channel_mix.2.mlp.2.bias', 'module.waffleiron.channel_mix.3.scale.weight', 'module.waffleiron.channel_mix.3.norm.weight', 'module.waffleiron.channel_mix.3.norm.bias', 'module.waffleiron.channel_mix.3.mlp.0.weight', 'module.waffleiron.channel_mix.3.mlp.0.bias', 'module.waffleiron.channel_mix.3.mlp.2.weight', 'module.waffleiron.channel_mix.3.mlp.2.bias', 'module.waffleiron.channel_mix.4.scale.weight', 'module.waffleiron.channel_mix.4.norm.weight', 'module.waffleiron.channel_mix.4.norm.bias', 'module.waffleiron.channel_mix.4.mlp.0.weight', 'module.waffleiron.channel_mix.4.mlp.0.bias', 'module.waffleiron.channel_mix.4.mlp.2.weight', 'module.waffleiron.channel_mix.4.mlp.2.bias', 'module.waffleiron.channel_mix.5.scale.weight', 'module.waffleiron.channel_mix.5.norm.weight', 'module.waffleiron.channel_mix.5.norm.bias', 'module.waffleiron.channel_mix.5.mlp.0.weight', 'module.waffleiron.channel_mix.5.mlp.0.bias', 'module.waffleiron.channel_mix.5.mlp.2.weight', 'module.waffleiron.channel_mix.5.mlp.2.bias', 'module.waffleiron.channel_mix.6.scale.weight', 'module.waffleiron.channel_mix.6.norm.weight', 'module.waffleiron.channel_mix.6.norm.bias', 'module.waffleiron.channel_mix.6.mlp.0.weight', 'module.waffleiron.channel_mix.6.mlp.0.bias', 'module.waffleiron.channel_mix.6.mlp.2.weight', 'module.waffleiron.channel_mix.6.mlp.2.bias', 'module.waffleiron.channel_mix.7.scale.weight', 'module.waffleiron.channel_mix.7.norm.weight', 'module.waffleiron.channel_mix.7.norm.bias', 'module.waffleiron.channel_mix.7.mlp.0.weight', 'module.waffleiron.channel_mix.7.mlp.0.bias', 'module.waffleiron.channel_mix.7.mlp.2.weight', 'module.waffleiron.channel_mix.7.mlp.2.bias', 'module.waffleiron.channel_mix.8.scale.weight', 'module.waffleiron.channel_mix.8.norm.weight', 'module.waffleiron.channel_mix.8.norm.bias', 'module.waffleiron.channel_mix.8.mlp.0.weight', 'module.waffleiron.channel_mix.8.mlp.0.bias', 'module.waffleiron.channel_mix.8.mlp.2.weight', 'module.waffleiron.channel_mix.8.mlp.2.bias', 'module.waffleiron.channel_mix.9.scale.weight', 'module.waffleiron.channel_mix.9.norm.weight', 'module.waffleiron.channel_mix.9.norm.bias', 'module.waffleiron.channel_mix.9.mlp.0.weight', 'module.waffleiron.channel_mix.9.mlp.0.bias', 'module.waffleiron.channel_mix.9.mlp.2.weight', 'module.waffleiron.channel_mix.9.mlp.2.bias', 'module.waffleiron.channel_mix.10.scale.weight', 'module.waffleiron.channel_mix.10.norm.weight', 'module.waffleiron.channel_mix.10.norm.bias', 'module.waffleiron.channel_mix.10.mlp.0.weight', 'module.waffleiron.channel_mix.10.mlp.0.bias', 'module.waffleiron.channel_mix.10.mlp.2.weight', 'module.waffleiron.channel_mix.10.mlp.2.bias', 'module.waffleiron.channel_mix.11.scale.weight', 'module.waffleiron.channel_mix.11.norm.weight', 'module.waffleiron.channel_mix.11.norm.bias', 'module.waffleiron.channel_mix.11.mlp.0.weight', 'module.waffleiron.channel_mix.11.mlp.0.bias', 'module.waffleiron.channel_mix.11.mlp.2.weight', 'module.waffleiron.channel_mix.11.mlp.2.bias', 'module.waffleiron.channel_mix.12.scale.weight', 'module.waffleiron.channel_mix.12.norm.weight', 'module.waffleiron.channel_mix.12.norm.bias', 'module.waffleiron.channel_mix.12.mlp.0.weight', 'module.waffleiron.channel_mix.12.mlp.0.bias', 'module.waffleiron.channel_mix.12.mlp.2.weight', 'module.waffleiron.channel_mix.12.mlp.2.bias', 'module.waffleiron.channel_mix.13.scale.weight', 'module.waffleiron.channel_mix.13.norm.weight', 'module.waffleiron.channel_mix.13.norm.bias', 'module.waffleiron.channel_mix.13.mlp.0.weight', 'module.waffleiron.channel_mix.13.mlp.0.bias', 'module.waffleiron.channel_mix.13.mlp.2.weight', 'module.waffleiron.channel_mix.13.mlp.2.bias', 'module.waffleiron.channel_mix.14.scale.weight', 'module.waffleiron.channel_mix.14.norm.weight', 'module.waffleiron.channel_mix.14.norm.bias', 'module.waffleiron.channel_mix.14.mlp.0.weight', 'module.waffleiron.channel_mix.14.mlp.0.bias', 'module.waffleiron.channel_mix.14.mlp.2.weight', 'module.waffleiron.channel_mix.14.mlp.2.bias', 'module.waffleiron.channel_mix.15.scale.weight', 'module.waffleiron.channel_mix.15.norm.weight', 'module.waffleiron.channel_mix.15.norm.bias', 'module.waffleiron.channel_mix.15.mlp.0.weight', 'module.waffleiron.channel_mix.15.mlp.0.bias', 'module.waffleiron.channel_mix.15.mlp.2.weight', 'module.waffleiron.channel_mix.15.mlp.2.bias', 'module.waffleiron.channel_mix.16.scale.weight', 'module.waffleiron.channel_mix.16.norm.weight', 'module.waffleiron.channel_mix.16.norm.bias', 'module.waffleiron.channel_mix.16.mlp.0.weight', 'module.waffleiron.channel_mix.16.mlp.0.bias', 'module.waffleiron.channel_mix.16.mlp.2.weight', 'module.waffleiron.channel_mix.16.mlp.2.bias', 'module.waffleiron.channel_mix.17.scale.weight', 'module.waffleiron.channel_mix.17.norm.weight', 'module.waffleiron.channel_mix.17.norm.bias', 'module.waffleiron.channel_mix.17.mlp.0.weight', 'module.waffleiron.channel_mix.17.mlp.0.bias', 'module.waffleiron.channel_mix.17.mlp.2.weight', 'module.waffleiron.channel_mix.17.mlp.2.bias', 'module.waffleiron.channel_mix.18.scale.weight', 'module.waffleiron.channel_mix.18.norm.weight', 'module.waffleiron.channel_mix.18.norm.bias', 'module.waffleiron.channel_mix.18.mlp.0.weight', 'module.waffleiron.channel_mix.18.mlp.0.bias', 'module.waffleiron.channel_mix.18.mlp.2.weight', 'module.waffleiron.channel_mix.18.mlp.2.bias', 'module.waffleiron.channel_mix.19.scale.weight', 'module.waffleiron.channel_mix.19.norm.weight', 'module.waffleiron.channel_mix.19.norm.bias', 'module.waffleiron.channel_mix.19.mlp.0.weight', 'module.waffleiron.channel_mix.19.mlp.0.bias', 'module.waffleiron.channel_mix.19.mlp.2.weight', 'module.waffleiron.channel_mix.19.mlp.2.bias', 'module.waffleiron.channel_mix.20.scale.weight', 'module.waffleiron.channel_mix.20.norm.weight', 'module.waffleiron.channel_mix.20.norm.bias', 'module.waffleiron.channel_mix.20.mlp.0.weight', 'module.waffleiron.channel_mix.20.mlp.0.bias', 'module.waffleiron.channel_mix.20.mlp.2.weight', 'module.waffleiron.channel_mix.20.mlp.2.bias', 'module.waffleiron.channel_mix.21.scale.weight', 'module.waffleiron.channel_mix.21.norm.weight', 'module.waffleiron.channel_mix.21.norm.bias', 'module.waffleiron.channel_mix.21.mlp.0.weight', 'module.waffleiron.channel_mix.21.mlp.0.bias', 'module.waffleiron.channel_mix.21.mlp.2.weight', 'module.waffleiron.channel_mix.21.mlp.2.bias', 'module.waffleiron.channel_mix.22.scale.weight', 'module.waffleiron.channel_mix.22.norm.weight', 'module.waffleiron.channel_mix.22.norm.bias', 'module.waffleiron.channel_mix.22.mlp.0.weight', 'module.waffleiron.channel_mix.22.mlp.0.bias', 'module.waffleiron.channel_mix.22.mlp.2.weight', 'module.waffleiron.channel_mix.22.mlp.2.bias', 'module.waffleiron.channel_mix.23.scale.weight', 'module.waffleiron.channel_mix.23.norm.weight', 'module.waffleiron.channel_mix.23.norm.bias', 'module.waffleiron.channel_mix.23.mlp.0.weight', 'module.waffleiron.channel_mix.23.mlp.0.bias', 'module.waffleiron.channel_mix.23.mlp.2.weight', 'module.waffleiron.channel_mix.23.mlp.2.bias', 'module.waffleiron.channel_mix.24.scale.weight', 'module.waffleiron.channel_mix.24.norm.weight', 'module.waffleiron.channel_mix.24.norm.bias', 'module.waffleiron.channel_mix.24.mlp.0.weight', 'module.waffleiron.channel_mix.24.mlp.0.bias', 'module.waffleiron.channel_mix.24.mlp.2.weight', 'module.waffleiron.channel_mix.24.mlp.2.bias', 'module.waffleiron.channel_mix.25.scale.weight', 'module.waffleiron.channel_mix.25.norm.weight', 'module.waffleiron.channel_mix.25.norm.bias', 'module.waffleiron.channel_mix.25.mlp.0.weight', 'module.waffleiron.channel_mix.25.mlp.0.bias', 'module.waffleiron.channel_mix.25.mlp.2.weight', 'module.waffleiron.channel_mix.25.mlp.2.bias', 'module.waffleiron.channel_mix.26.scale.weight', 'module.waffleiron.channel_mix.26.norm.weight', 'module.waffleiron.channel_mix.26.norm.bias', 'module.waffleiron.channel_mix.26.mlp.0.weight', 'module.waffleiron.channel_mix.26.mlp.0.bias', 'module.waffleiron.channel_mix.26.mlp.2.weight', 'module.waffleiron.channel_mix.26.mlp.2.bias', 'module.waffleiron.channel_mix.27.scale.weight', 'module.waffleiron.channel_mix.27.norm.weight', 'module.waffleiron.channel_mix.27.norm.bias', 'module.waffleiron.channel_mix.27.mlp.0.weight', 'module.waffleiron.channel_mix.27.mlp.0.bias', 'module.waffleiron.channel_mix.27.mlp.2.weight', 'module.waffleiron.channel_mix.27.mlp.2.bias', 'module.waffleiron.channel_mix.28.scale.weight', 'module.waffleiron.channel_mix.28.norm.weight', 'module.waffleiron.channel_mix.28.norm.bias', 'module.waffleiron.channel_mix.28.mlp.0.weight', 'module.waffleiron.channel_mix.28.mlp.0.bias', 'module.waffleiron.channel_mix.28.mlp.2.weight', 'module.waffleiron.channel_mix.28.mlp.2.bias', 'module.waffleiron.channel_mix.29.scale.weight', 'module.waffleiron.channel_mix.29.norm.weight', 'module.waffleiron.channel_mix.29.norm.bias', 'module.waffleiron.channel_mix.29.mlp.0.weight', 'module.waffleiron.channel_mix.29.mlp.0.bias', 'module.waffleiron.channel_mix.29.mlp.2.weight', 'module.waffleiron.channel_mix.29.mlp.2.bias', 'module.waffleiron.channel_mix.30.scale.weight', 'module.waffleiron.channel_mix.30.norm.weight', 'module.waffleiron.channel_mix.30.norm.bias', 'module.waffleiron.channel_mix.30.mlp.0.weight', 'module.waffleiron.channel_mix.30.mlp.0.bias', 'module.waffleiron.channel_mix.30.mlp.2.weight', 'module.waffleiron.channel_mix.30.mlp.2.bias', 'module.waffleiron.channel_mix.31.scale.weight', 'module.waffleiron.channel_mix.31.norm.weight', 'module.waffleiron.channel_mix.31.norm.bias', 'module.waffleiron.channel_mix.31.mlp.0.weight', 'module.waffleiron.channel_mix.31.mlp.0.bias', 'module.waffleiron.channel_mix.31.mlp.2.weight', 'module.waffleiron.channel_mix.31.mlp.2.bias', 'module.waffleiron.channel_mix.32.scale.weight', 'module.waffleiron.channel_mix.32.norm.weight', 'module.waffleiron.channel_mix.32.norm.bias', 'module.waffleiron.channel_mix.32.mlp.0.weight', 'module.waffleiron.channel_mix.32.mlp.0.bias', 'module.waffleiron.channel_mix.32.mlp.2.weight', 'module.waffleiron.channel_mix.32.mlp.2.bias', 'module.waffleiron.channel_mix.33.scale.weight', 'module.waffleiron.channel_mix.33.norm.weight', 'module.waffleiron.channel_mix.33.norm.bias', 'module.waffleiron.channel_mix.33.mlp.0.weight', 'module.waffleiron.channel_mix.33.mlp.0.bias', 'module.waffleiron.channel_mix.33.mlp.2.weight', 'module.waffleiron.channel_mix.33.mlp.2.bias', 'module.waffleiron.channel_mix.34.scale.weight', 'module.waffleiron.channel_mix.34.norm.weight', 'module.waffleiron.channel_mix.34.norm.bias', 'module.waffleiron.channel_mix.34.mlp.0.weight', 'module.waffleiron.channel_mix.34.mlp.0.bias', 'module.waffleiron.channel_mix.34.mlp.2.weight', 'module.waffleiron.channel_mix.34.mlp.2.bias', 'module.waffleiron.channel_mix.35.scale.weight', 'module.waffleiron.channel_mix.35.norm.weight', 'module.waffleiron.channel_mix.35.norm.bias', 'module.waffleiron.channel_mix.35.mlp.0.weight', 'module.waffleiron.channel_mix.35.mlp.0.bias', 'module.waffleiron.channel_mix.35.mlp.2.weight', 'module.waffleiron.channel_mix.35.mlp.2.bias', 'module.waffleiron.channel_mix.36.scale.weight', 'module.waffleiron.channel_mix.36.norm.weight', 'module.waffleiron.channel_mix.36.norm.bias', 'module.waffleiron.channel_mix.36.mlp.0.weight', 'module.waffleiron.channel_mix.36.mlp.0.bias', 'module.waffleiron.channel_mix.36.mlp.2.weight', 'module.waffleiron.channel_mix.36.mlp.2.bias', 'module.waffleiron.channel_mix.37.scale.weight', 'module.waffleiron.channel_mix.37.norm.weight', 'module.waffleiron.channel_mix.37.norm.bias', 'module.waffleiron.channel_mix.37.mlp.0.weight', 'module.waffleiron.channel_mix.37.mlp.0.bias', 'module.waffleiron.channel_mix.37.mlp.2.weight', 'module.waffleiron.channel_mix.37.mlp.2.bias', 'module.waffleiron.channel_mix.38.scale.weight', 'module.waffleiron.channel_mix.38.norm.weight', 'module.waffleiron.channel_mix.38.norm.bias', 'module.waffleiron.channel_mix.38.mlp.0.weight', 'module.waffleiron.channel_mix.38.mlp.0.bias', 'module.waffleiron.channel_mix.38.mlp.2.weight', 'module.waffleiron.channel_mix.38.mlp.2.bias', 'module.waffleiron.channel_mix.39.scale.weight', 'module.waffleiron.channel_mix.39.norm.weight', 'module.waffleiron.channel_mix.39.norm.bias', 'module.waffleiron.channel_mix.39.mlp.0.weight', 'module.waffleiron.channel_mix.39.mlp.0.bias', 'module.waffleiron.channel_mix.39.mlp.2.weight', 'module.waffleiron.channel_mix.39.mlp.2.bias', 'module.waffleiron.channel_mix.40.scale.weight', 'module.waffleiron.channel_mix.40.norm.weight', 'module.waffleiron.channel_mix.40.norm.bias', 'module.waffleiron.channel_mix.40.mlp.0.weight', 'module.waffleiron.channel_mix.40.mlp.0.bias', 'module.waffleiron.channel_mix.40.mlp.2.weight', 'module.waffleiron.channel_mix.40.mlp.2.bias', 'module.waffleiron.channel_mix.41.scale.weight', 'module.waffleiron.channel_mix.41.norm.weight', 'module.waffleiron.channel_mix.41.norm.bias', 'module.waffleiron.channel_mix.41.mlp.0.weight', 'module.waffleiron.channel_mix.41.mlp.0.bias', 'module.waffleiron.channel_mix.41.mlp.2.weight', 'module.waffleiron.channel_mix.41.mlp.2.bias', 'module.waffleiron.channel_mix.42.scale.weight', 'module.waffleiron.channel_mix.42.norm.weight', 'module.waffleiron.channel_mix.42.norm.bias', 'module.waffleiron.channel_mix.42.mlp.0.weight', 'module.waffleiron.channel_mix.42.mlp.0.bias', 'module.waffleiron.channel_mix.42.mlp.2.weight', 'module.waffleiron.channel_mix.42.mlp.2.bias', 'module.waffleiron.channel_mix.43.scale.weight', 'module.waffleiron.channel_mix.43.norm.weight', 'module.waffleiron.channel_mix.43.norm.bias', 'module.waffleiron.channel_mix.43.mlp.0.weight', 'module.waffleiron.channel_mix.43.mlp.0.bias', 'module.waffleiron.channel_mix.43.mlp.2.weight', 'module.waffleiron.channel_mix.43.mlp.2.bias', 'module.waffleiron.channel_mix.44.scale.weight', 'module.waffleiron.channel_mix.44.norm.weight', 'module.waffleiron.channel_mix.44.norm.bias', 'module.waffleiron.channel_mix.44.mlp.0.weight', 'module.waffleiron.channel_mix.44.mlp.0.bias', 'module.waffleiron.channel_mix.44.mlp.2.weight', 'module.waffleiron.channel_mix.44.mlp.2.bias', 'module.waffleiron.channel_mix.45.scale.weight', 'module.waffleiron.channel_mix.45.norm.weight', 'module.waffleiron.channel_mix.45.norm.bias', 'module.waffleiron.channel_mix.45.mlp.0.weight', 'module.waffleiron.channel_mix.45.mlp.0.bias', 'module.waffleiron.channel_mix.45.mlp.2.weight', 'module.waffleiron.channel_mix.45.mlp.2.bias', 'module.waffleiron.channel_mix.46.scale.weight', 'module.waffleiron.channel_mix.46.norm.weight', 'module.waffleiron.channel_mix.46.norm.bias', 'module.waffleiron.channel_mix.46.mlp.0.weight', 'module.waffleiron.channel_mix.46.mlp.0.bias', 'module.waffleiron.channel_mix.46.mlp.2.weight', 'module.waffleiron.channel_mix.46.mlp.2.bias', 'module.waffleiron.channel_mix.47.scale.weight', 'module.waffleiron.channel_mix.47.norm.weight', 'module.waffleiron.channel_mix.47.norm.bias', 'module.waffleiron.channel_mix.47.mlp.0.weight', 'module.waffleiron.channel_mix.47.mlp.0.bias', 'module.waffleiron.channel_mix.47.mlp.2.weight', 'module.waffleiron.channel_mix.47.mlp.2.bias', 'module.waffleiron.spatial_mix.0.scale.weight', 'module.waffleiron.spatial_mix.0.norm.weight', 'module.waffleiron.spatial_mix.0.norm.bias', 'module.waffleiron.spatial_mix.0.ffn.0.weight', 'module.waffleiron.spatial_mix.0.ffn.0.bias', 'module.waffleiron.spatial_mix.0.ffn.2.weight', 'module.waffleiron.spatial_mix.0.ffn.2.bias', 'module.waffleiron.spatial_mix.1.scale.weight', 'module.waffleiron.spatial_mix.1.norm.weight', 'module.waffleiron.spatial_mix.1.norm.bias', 'module.waffleiron.spatial_mix.1.ffn.0.weight', 'module.waffleiron.spatial_mix.1.ffn.0.bias', 'module.waffleiron.spatial_mix.1.ffn.2.weight', 'module.waffleiron.spatial_mix.1.ffn.2.bias', 'module.waffleiron.spatial_mix.2.scale.weight', 'module.waffleiron.spatial_mix.2.norm.weight', 'module.waffleiron.spatial_mix.2.norm.bias', 'module.waffleiron.spatial_mix.2.ffn.0.weight', 'module.waffleiron.spatial_mix.2.ffn.0.bias', 'module.waffleiron.spatial_mix.2.ffn.2.weight', 'module.waffleiron.spatial_mix.2.ffn.2.bias', 'module.waffleiron.spatial_mix.3.scale.weight', 'module.waffleiron.spatial_mix.3.norm.weight', 'module.waffleiron.spatial_mix.3.norm.bias', 'module.waffleiron.spatial_mix.3.ffn.0.weight', 'module.waffleiron.spatial_mix.3.ffn.0.bias', 'module.waffleiron.spatial_mix.3.ffn.2.weight', 'module.waffleiron.spatial_mix.3.ffn.2.bias', 'module.waffleiron.spatial_mix.4.scale.weight', 'module.waffleiron.spatial_mix.4.norm.weight', 'module.waffleiron.spatial_mix.4.norm.bias', 'module.waffleiron.spatial_mix.4.ffn.0.weight', 'module.waffleiron.spatial_mix.4.ffn.0.bias', 'module.waffleiron.spatial_mix.4.ffn.2.weight', 'module.waffleiron.spatial_mix.4.ffn.2.bias', 'module.waffleiron.spatial_mix.5.scale.weight', 'module.waffleiron.spatial_mix.5.norm.weight', 'module.waffleiron.spatial_mix.5.norm.bias', 'module.waffleiron.spatial_mix.5.ffn.0.weight', 'module.waffleiron.spatial_mix.5.ffn.0.bias', 'module.waffleiron.spatial_mix.5.ffn.2.weight', 'module.waffleiron.spatial_mix.5.ffn.2.bias', 'module.waffleiron.spatial_mix.6.scale.weight', 'module.waffleiron.spatial_mix.6.norm.weight', 'module.waffleiron.spatial_mix.6.norm.bias', 'module.waffleiron.spatial_mix.6.ffn.0.weight', 'module.waffleiron.spatial_mix.6.ffn.0.bias', 'module.waffleiron.spatial_mix.6.ffn.2.weight', 'module.waffleiron.spatial_mix.6.ffn.2.bias', 'module.waffleiron.spatial_mix.7.scale.weight', 'module.waffleiron.spatial_mix.7.norm.weight', 'module.waffleiron.spatial_mix.7.norm.bias', 'module.waffleiron.spatial_mix.7.ffn.0.weight', 'module.waffleiron.spatial_mix.7.ffn.0.bias', 'module.waffleiron.spatial_mix.7.ffn.2.weight', 'module.waffleiron.spatial_mix.7.ffn.2.bias', 'module.waffleiron.spatial_mix.8.scale.weight', 'module.waffleiron.spatial_mix.8.norm.weight', 'module.waffleiron.spatial_mix.8.norm.bias', 'module.waffleiron.spatial_mix.8.ffn.0.weight', 'module.waffleiron.spatial_mix.8.ffn.0.bias', 'module.waffleiron.spatial_mix.8.ffn.2.weight', 'module.waffleiron.spatial_mix.8.ffn.2.bias', 'module.waffleiron.spatial_mix.9.scale.weight', 'module.waffleiron.spatial_mix.9.norm.weight', 'module.waffleiron.spatial_mix.9.norm.bias', 'module.waffleiron.spatial_mix.9.ffn.0.weight', 'module.waffleiron.spatial_mix.9.ffn.0.bias', 'module.waffleiron.spatial_mix.9.ffn.2.weight', 'module.waffleiron.spatial_mix.9.ffn.2.bias', 'module.waffleiron.spatial_mix.10.scale.weight', 'module.waffleiron.spatial_mix.10.norm.weight', 'module.waffleiron.spatial_mix.10.norm.bias', 'module.waffleiron.spatial_mix.10.ffn.0.weight', 'module.waffleiron.spatial_mix.10.ffn.0.bias', 'module.waffleiron.spatial_mix.10.ffn.2.weight', 'module.waffleiron.spatial_mix.10.ffn.2.bias', 'module.waffleiron.spatial_mix.11.scale.weight', 'module.waffleiron.spatial_mix.11.norm.weight', 'module.waffleiron.spatial_mix.11.norm.bias', 'module.waffleiron.spatial_mix.11.ffn.0.weight', 'module.waffleiron.spatial_mix.11.ffn.0.bias', 'module.waffleiron.spatial_mix.11.ffn.2.weight', 'module.waffleiron.spatial_mix.11.ffn.2.bias', 'module.waffleiron.spatial_mix.12.scale.weight', 'module.waffleiron.spatial_mix.12.norm.weight', 'module.waffleiron.spatial_mix.12.norm.bias', 'module.waffleiron.spatial_mix.12.ffn.0.weight', 'module.waffleiron.spatial_mix.12.ffn.0.bias', 'module.waffleiron.spatial_mix.12.ffn.2.weight', 'module.waffleiron.spatial_mix.12.ffn.2.bias', 'module.waffleiron.spatial_mix.13.scale.weight', 'module.waffleiron.spatial_mix.13.norm.weight', 'module.waffleiron.spatial_mix.13.norm.bias', 'module.waffleiron.spatial_mix.13.ffn.0.weight', 'module.waffleiron.spatial_mix.13.ffn.0.bias', 'module.waffleiron.spatial_mix.13.ffn.2.weight', 'module.waffleiron.spatial_mix.13.ffn.2.bias', 'module.waffleiron.spatial_mix.14.scale.weight', 'module.waffleiron.spatial_mix.14.norm.weight', 'module.waffleiron.spatial_mix.14.norm.bias', 'module.waffleiron.spatial_mix.14.ffn.0.weight', 'module.waffleiron.spatial_mix.14.ffn.0.bias', 'module.waffleiron.spatial_mix.14.ffn.2.weight', 'module.waffleiron.spatial_mix.14.ffn.2.bias', 'module.waffleiron.spatial_mix.15.scale.weight', 'module.waffleiron.spatial_mix.15.norm.weight', 'module.waffleiron.spatial_mix.15.norm.bias', 'module.waffleiron.spatial_mix.15.ffn.0.weight', 'module.waffleiron.spatial_mix.15.ffn.0.bias', 'module.waffleiron.spatial_mix.15.ffn.2.weight', 'module.waffleiron.spatial_mix.15.ffn.2.bias', 'module.waffleiron.spatial_mix.16.scale.weight', 'module.waffleiron.spatial_mix.16.norm.weight', 'module.waffleiron.spatial_mix.16.norm.bias', 'module.waffleiron.spatial_mix.16.ffn.0.weight', 'module.waffleiron.spatial_mix.16.ffn.0.bias', 'module.waffleiron.spatial_mix.16.ffn.2.weight', 'module.waffleiron.spatial_mix.16.ffn.2.bias', 'module.waffleiron.spatial_mix.17.scale.weight', 'module.waffleiron.spatial_mix.17.norm.weight', 'module.waffleiron.spatial_mix.17.norm.bias', 'module.waffleiron.spatial_mix.17.ffn.0.weight', 'module.waffleiron.spatial_mix.17.ffn.0.bias', 'module.waffleiron.spatial_mix.17.ffn.2.weight', 'module.waffleiron.spatial_mix.17.ffn.2.bias', 'module.waffleiron.spatial_mix.18.scale.weight', 'module.waffleiron.spatial_mix.18.norm.weight', 'module.waffleiron.spatial_mix.18.norm.bias', 'module.waffleiron.spatial_mix.18.ffn.0.weight', 'module.waffleiron.spatial_mix.18.ffn.0.bias', 'module.waffleiron.spatial_mix.18.ffn.2.weight', 'module.waffleiron.spatial_mix.18.ffn.2.bias', 'module.waffleiron.spatial_mix.19.scale.weight', 'module.waffleiron.spatial_mix.19.norm.weight', 'module.waffleiron.spatial_mix.19.norm.bias', 'module.waffleiron.spatial_mix.19.ffn.0.weight', 'module.waffleiron.spatial_mix.19.ffn.0.bias', 'module.waffleiron.spatial_mix.19.ffn.2.weight', 'module.waffleiron.spatial_mix.19.ffn.2.bias', 'module.waffleiron.spatial_mix.20.scale.weight', 'module.waffleiron.spatial_mix.20.norm.weight', 'module.waffleiron.spatial_mix.20.norm.bias', 'module.waffleiron.spatial_mix.20.ffn.0.weight', 'module.waffleiron.spatial_mix.20.ffn.0.bias', 'module.waffleiron.spatial_mix.20.ffn.2.weight', 'module.waffleiron.spatial_mix.20.ffn.2.bias', 'module.waffleiron.spatial_mix.21.scale.weight', 'module.waffleiron.spatial_mix.21.norm.weight', 'module.waffleiron.spatial_mix.21.norm.bias', 'module.waffleiron.spatial_mix.21.ffn.0.weight', 'module.waffleiron.spatial_mix.21.ffn.0.bias', 'module.waffleiron.spatial_mix.21.ffn.2.weight', 'module.waffleiron.spatial_mix.21.ffn.2.bias', 'module.waffleiron.spatial_mix.22.scale.weight', 'module.waffleiron.spatial_mix.22.norm.weight', 'module.waffleiron.spatial_mix.22.norm.bias', 'module.waffleiron.spatial_mix.22.ffn.0.weight', 'module.waffleiron.spatial_mix.22.ffn.0.bias', 'module.waffleiron.spatial_mix.22.ffn.2.weight', 'module.waffleiron.spatial_mix.22.ffn.2.bias', 'module.waffleiron.spatial_mix.23.scale.weight', 'module.waffleiron.spatial_mix.23.norm.weight', 'module.waffleiron.spatial_mix.23.norm.bias', 'module.waffleiron.spatial_mix.23.ffn.0.weight', 'module.waffleiron.spatial_mix.23.ffn.0.bias', 'module.waffleiron.spatial_mix.23.ffn.2.weight', 'module.waffleiron.spatial_mix.23.ffn.2.bias', 'module.waffleiron.spatial_mix.24.scale.weight', 'module.waffleiron.spatial_mix.24.norm.weight', 'module.waffleiron.spatial_mix.24.norm.bias', 'module.waffleiron.spatial_mix.24.ffn.0.weight', 'module.waffleiron.spatial_mix.24.ffn.0.bias', 'module.waffleiron.spatial_mix.24.ffn.2.weight', 'module.waffleiron.spatial_mix.24.ffn.2.bias', 'module.waffleiron.spatial_mix.25.scale.weight', 'module.waffleiron.spatial_mix.25.norm.weight', 'module.waffleiron.spatial_mix.25.norm.bias', 'module.waffleiron.spatial_mix.25.ffn.0.weight', 'module.waffleiron.spatial_mix.25.ffn.0.bias', 'module.waffleiron.spatial_mix.25.ffn.2.weight', 'module.waffleiron.spatial_mix.25.ffn.2.bias', 'module.waffleiron.spatial_mix.26.scale.weight', 'module.waffleiron.spatial_mix.26.norm.weight', 'module.waffleiron.spatial_mix.26.norm.bias', 'module.waffleiron.spatial_mix.26.ffn.0.weight', 'module.waffleiron.spatial_mix.26.ffn.0.bias', 'module.waffleiron.spatial_mix.26.ffn.2.weight', 'module.waffleiron.spatial_mix.26.ffn.2.bias', 'module.waffleiron.spatial_mix.27.scale.weight', 'module.waffleiron.spatial_mix.27.norm.weight', 'module.waffleiron.spatial_mix.27.norm.bias', 'module.waffleiron.spatial_mix.27.ffn.0.weight', 'module.waffleiron.spatial_mix.27.ffn.0.bias', 'module.waffleiron.spatial_mix.27.ffn.2.weight', 'module.waffleiron.spatial_mix.27.ffn.2.bias', 'module.waffleiron.spatial_mix.28.scale.weight', 'module.waffleiron.spatial_mix.28.norm.weight', 'module.waffleiron.spatial_mix.28.norm.bias', 'module.waffleiron.spatial_mix.28.ffn.0.weight', 'module.waffleiron.spatial_mix.28.ffn.0.bias', 'module.waffleiron.spatial_mix.28.ffn.2.weight', 'module.waffleiron.spatial_mix.28.ffn.2.bias', 'module.waffleiron.spatial_mix.29.scale.weight', 'module.waffleiron.spatial_mix.29.norm.weight', 'module.waffleiron.spatial_mix.29.norm.bias', 'module.waffleiron.spatial_mix.29.ffn.0.weight', 'module.waffleiron.spatial_mix.29.ffn.0.bias', 'module.waffleiron.spatial_mix.29.ffn.2.weight', 'module.waffleiron.spatial_mix.29.ffn.2.bias', 'module.waffleiron.spatial_mix.30.scale.weight', 'module.waffleiron.spatial_mix.30.norm.weight', 'module.waffleiron.spatial_mix.30.norm.bias', 'module.waffleiron.spatial_mix.30.ffn.0.weight', 'module.waffleiron.spatial_mix.30.ffn.0.bias', 'module.waffleiron.spatial_mix.30.ffn.2.weight', 'module.waffleiron.spatial_mix.30.ffn.2.bias', 'module.waffleiron.spatial_mix.31.scale.weight', 'module.waffleiron.spatial_mix.31.norm.weight', 'module.waffleiron.spatial_mix.31.norm.bias', 'module.waffleiron.spatial_mix.31.ffn.0.weight', 'module.waffleiron.spatial_mix.31.ffn.0.bias', 'module.waffleiron.spatial_mix.31.ffn.2.weight', 'module.waffleiron.spatial_mix.31.ffn.2.bias', 'module.waffleiron.spatial_mix.32.scale.weight', 'module.waffleiron.spatial_mix.32.norm.weight', 'module.waffleiron.spatial_mix.32.norm.bias', 'module.waffleiron.spatial_mix.32.ffn.0.weight', 'module.waffleiron.spatial_mix.32.ffn.0.bias', 'module.waffleiron.spatial_mix.32.ffn.2.weight', 'module.waffleiron.spatial_mix.32.ffn.2.bias', 'module.waffleiron.spatial_mix.33.scale.weight', 'module.waffleiron.spatial_mix.33.norm.weight', 'module.waffleiron.spatial_mix.33.norm.bias', 'module.waffleiron.spatial_mix.33.ffn.0.weight', 'module.waffleiron.spatial_mix.33.ffn.0.bias', 'module.waffleiron.spatial_mix.33.ffn.2.weight', 'module.waffleiron.spatial_mix.33.ffn.2.bias', 'module.waffleiron.spatial_mix.34.scale.weight', 'module.waffleiron.spatial_mix.34.norm.weight', 'module.waffleiron.spatial_mix.34.norm.bias', 'module.waffleiron.spatial_mix.34.ffn.0.weight', 'module.waffleiron.spatial_mix.34.ffn.0.bias', 'module.waffleiron.spatial_mix.34.ffn.2.weight', 'module.waffleiron.spatial_mix.34.ffn.2.bias', 'module.waffleiron.spatial_mix.35.scale.weight', 'module.waffleiron.spatial_mix.35.norm.weight', 'module.waffleiron.spatial_mix.35.norm.bias', 'module.waffleiron.spatial_mix.35.ffn.0.weight', 'module.waffleiron.spatial_mix.35.ffn.0.bias', 'module.waffleiron.spatial_mix.35.ffn.2.weight', 'module.waffleiron.spatial_mix.35.ffn.2.bias', 'module.waffleiron.spatial_mix.36.scale.weight', 'module.waffleiron.spatial_mix.36.norm.weight', 'module.waffleiron.spatial_mix.36.norm.bias', 'module.waffleiron.spatial_mix.36.ffn.0.weight', 'module.waffleiron.spatial_mix.36.ffn.0.bias', 'module.waffleiron.spatial_mix.36.ffn.2.weight', 'module.waffleiron.spatial_mix.36.ffn.2.bias', 'module.waffleiron.spatial_mix.37.scale.weight', 'module.waffleiron.spatial_mix.37.norm.weight', 'module.waffleiron.spatial_mix.37.norm.bias', 'module.waffleiron.spatial_mix.37.ffn.0.weight', 'module.waffleiron.spatial_mix.37.ffn.0.bias', 'module.waffleiron.spatial_mix.37.ffn.2.weight', 'module.waffleiron.spatial_mix.37.ffn.2.bias', 'module.waffleiron.spatial_mix.38.scale.weight', 'module.waffleiron.spatial_mix.38.norm.weight', 'module.waffleiron.spatial_mix.38.norm.bias', 'module.waffleiron.spatial_mix.38.ffn.0.weight', 'module.waffleiron.spatial_mix.38.ffn.0.bias', 'module.waffleiron.spatial_mix.38.ffn.2.weight', 'module.waffleiron.spatial_mix.38.ffn.2.bias', 'module.waffleiron.spatial_mix.39.scale.weight', 'module.waffleiron.spatial_mix.39.norm.weight', 'module.waffleiron.spatial_mix.39.norm.bias', 'module.waffleiron.spatial_mix.39.ffn.0.weight', 'module.waffleiron.spatial_mix.39.ffn.0.bias', 'module.waffleiron.spatial_mix.39.ffn.2.weight', 'module.waffleiron.spatial_mix.39.ffn.2.bias', 'module.waffleiron.spatial_mix.40.scale.weight', 'module.waffleiron.spatial_mix.40.norm.weight', 'module.waffleiron.spatial_mix.40.norm.bias', 'module.waffleiron.spatial_mix.40.ffn.0.weight', 'module.waffleiron.spatial_mix.40.ffn.0.bias', 'module.waffleiron.spatial_mix.40.ffn.2.weight', 'module.waffleiron.spatial_mix.40.ffn.2.bias', 'module.waffleiron.spatial_mix.41.scale.weight', 'module.waffleiron.spatial_mix.41.norm.weight', 'module.waffleiron.spatial_mix.41.norm.bias', 'module.waffleiron.spatial_mix.41.ffn.0.weight', 'module.waffleiron.spatial_mix.41.ffn.0.bias', 'module.waffleiron.spatial_mix.41.ffn.2.weight', 'module.waffleiron.spatial_mix.41.ffn.2.bias', 'module.waffleiron.spatial_mix.42.scale.weight', 'module.waffleiron.spatial_mix.42.norm.weight', 'module.waffleiron.spatial_mix.42.norm.bias', 'module.waffleiron.spatial_mix.42.ffn.0.weight', 'module.waffleiron.spatial_mix.42.ffn.0.bias', 'module.waffleiron.spatial_mix.42.ffn.2.weight', 'module.waffleiron.spatial_mix.42.ffn.2.bias', 'module.waffleiron.spatial_mix.43.scale.weight', 'module.waffleiron.spatial_mix.43.norm.weight', 'module.waffleiron.spatial_mix.43.norm.bias', 'module.waffleiron.spatial_mix.43.ffn.0.weight', 'module.waffleiron.spatial_mix.43.ffn.0.bias', 'module.waffleiron.spatial_mix.43.ffn.2.weight', 'module.waffleiron.spatial_mix.43.ffn.2.bias', 'module.waffleiron.spatial_mix.44.scale.weight', 'module.waffleiron.spatial_mix.44.norm.weight', 'module.waffleiron.spatial_mix.44.norm.bias', 'module.waffleiron.spatial_mix.44.ffn.0.weight', 'module.waffleiron.spatial_mix.44.ffn.0.bias', 'module.waffleiron.spatial_mix.44.ffn.2.weight', 'module.waffleiron.spatial_mix.44.ffn.2.bias', 'module.waffleiron.spatial_mix.45.scale.weight', 'module.waffleiron.spatial_mix.45.norm.weight', 'module.waffleiron.spatial_mix.45.norm.bias', 'module.waffleiron.spatial_mix.45.ffn.0.weight', 'module.waffleiron.spatial_mix.45.ffn.0.bias', 'module.waffleiron.spatial_mix.45.ffn.2.weight', 'module.waffleiron.spatial_mix.45.ffn.2.bias', 'module.waffleiron.spatial_mix.46.scale.weight', 'module.waffleiron.spatial_mix.46.norm.weight', 'module.waffleiron.spatial_mix.46.norm.bias', 'module.waffleiron.spatial_mix.46.ffn.0.weight', 'module.waffleiron.spatial_mix.46.ffn.0.bias', 'module.waffleiron.spatial_mix.46.ffn.2.weight', 'module.waffleiron.spatial_mix.46.ffn.2.bias', 'module.waffleiron.spatial_mix.47.scale.weight', 'module.waffleiron.spatial_mix.47.norm.weight', 'module.waffleiron.spatial_mix.47.norm.bias', 'module.waffleiron.spatial_mix.47.ffn.0.weight', 'module.waffleiron.spatial_mix.47.ffn.0.bias', 'module.waffleiron.spatial_mix.47.ffn.2.weight', 'module.waffleiron.spatial_mix.47.ffn.2.bias', 'module.classif.0.weight', 'module.classif.0.bias', 'module.classif.0.running_mean', 'module.classif.0.running_var', 'module.classif.0.num_batches_tracked', 'module.classif.1.weight', 'module.classif.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c587871",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt = {}\n",
    "for k in ckpt.keys():\n",
    "    if k.startswith(\"module\"):\n",
    "        if k.startswith(\"module.classif.0\"):\n",
    "            continue\n",
    "        elif k.startswith(\"module.classif.1\"):\n",
    "            new_ckpt[\"classif\" + k[len(\"module.classif.1\") :]] = ckpt[k]\n",
    "        else:\n",
    "            new_ckpt[k[len(\"module.\") :]] = ckpt[k]\n",
    "    else:\n",
    "        new_ckpt[k] = ckpt[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a10e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ckpt.get(\"classif.weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca00085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84e7d8",
   "metadata": {},
   "source": [
    "## Model loaded --> Test features somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from auxiliary.process_data.nuscenes.nuscenes_dataset import DatasetTrainVal\n",
    "\n",
    "print(\"Creating dataloader...\", flush=True)\n",
    "\n",
    "target = '/root/main/dataset/processed'\n",
    "\n",
    "filelist_train = [os.path.join(target, 'train_pointclouds', fname) for fname in os.listdir(os.path.join(target, 'train_pointclouds')) if os.path.splitext(fname)[1]==\".npy\"]\n",
    "filelist_train.sort()\n",
    "filelist_val = filelist_train[:3]\n",
    "filelist_train = filelist_train[3:]\n",
    "\n",
    "ds = DatasetTrainVal(filelist_train, os.path.join(target, 'train_pointclouds'),\n",
    "                            training=True,\n",
    "                            npoints=2000,\n",
    "                            iteration_number=(2*10)*10,\n",
    "                            jitter=0.2)\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, # Change batch_size\n",
    "                                    num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2884a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_loader:\n",
    "    print(torch.bincount(t['target'][0]))\n",
    "    x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8d1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_filenames = [\"Lille1_1.ply\",  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",]\n",
    "destdir = '/root/main/dataset/processed/'\n",
    "rootdir = '/root/main/dataset/'\n",
    "\n",
    "filenames = train_filenames\n",
    "save_dir = os.path.join(destdir,\"train_pointclouds\")\n",
    "pts_all = {}\n",
    "for filename in filenames:\n",
    "    fname = os.path.join(rootdir, \"training_10_classes\", filename)\n",
    "    plydata = PlyData.read(fname)\n",
    "    x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "    y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "    z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "    reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "    label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "    pts = np.concatenate([\n",
    "        np.expand_dims(x,1),\n",
    "        np.expand_dims(y,1),\n",
    "        np.expand_dims(z,1),\n",
    "        np.expand_dims(reflectance,1),\n",
    "        np.expand_dims(label,1),\n",
    "    ], axis=1).astype(np.float32)\n",
    "    pts_all[filename] = pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfc59a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  83.03686 ,   83.05253 ,   83.117584, ..., -386.54715 ,\n",
       "       -386.5629  , -386.97958 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_all[\"Lille1_1.ply\"][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-360.1785\n",
      "67.185555\n",
      "-412.13937\n",
      "101.893524\n",
      "32.78496\n",
      "66.74454\n"
     ]
    }
   ],
   "source": [
    "print(min(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,2]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4331e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.701644699999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(101.893524 - (-412.13937))/20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e96dcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 25 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01441ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.705505\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6416d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.756725\n"
     ]
    }
   ],
   "source": [
    "print(np.std(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pc_here = torch.from_numpy(pts_all[\"Lille1_1.ply\"]).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize_pointcloud(points, voxel_size):\n",
    "    \"\"\"\n",
    "    Voxelizes a point cloud.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): The point cloud as an Nx3 array of XYZ coordinates.\n",
    "        voxel_size (float): The size of the voxels (uniform along all axes).\n",
    "        \n",
    "    Returns:\n",
    "        voxel_indices (np.ndarray): The voxel indices for each point.\n",
    "        voxel_grid (dict): A dictionary where keys are voxel indices (tuples) and values are points in that voxel.\n",
    "    \"\"\"\n",
    "    # Normalize points by voxel size\n",
    "    voxel_indices = np.floor(points[:,:3] / voxel_size).astype(np.int32)\n",
    "    \n",
    "    # Create a dictionary to store points in each voxel\n",
    "    voxel_grid = {}\n",
    "    \n",
    "    for idx, voxel in tqdm(enumerate(voxel_indices)):\n",
    "        voxel_key = tuple(voxel)  # Use tuple to make it hashable for the dictionary\n",
    "        if voxel_key not in voxel_grid:\n",
    "            voxel_grid[voxel_key] = []\n",
    "        voxel_grid[voxel_key].append(points[idx])\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    for key in voxel_grid:\n",
    "        voxel_grid[key] = np.array(voxel_grid[key])\n",
    "    \n",
    "    return voxel_indices, voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9efe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#point_cloud = np.random.rand(1000, 3) * 100  # 1000 points in a 100x100x100 space\n",
    "voxel_size = 20.0  # Voxel size of 5 units\n",
    "\n",
    "# Voxelize the point cloud\n",
    "voxel_indices, voxel_grid = voxelize_pointcloud(pts_all[\"Lille1_1.ply\"], voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results\n",
    "print(\"Voxel indices:\\n\", voxel_indices[900])  # Show first 10 voxel indices\n",
    "print(\"\\nNumber of unique voxels:\", len(voxel_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    if len(voxel_grid[i]) < 100:\n",
    "        voxel_grid.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    voxel_grid[i][:,4] = voxel_grid[i][:,4] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(voxel_grid[i][:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f2c3d",
   "metadata": {},
   "source": [
    "## Model Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c4ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(\"cuda:0\")\n",
    "model = model.cuda(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e309a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Conv1d(768, 16, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d10d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils.transforms as tr\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import os\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "class PCDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rootdir=None,\n",
    "        phase=\"train\",\n",
    "        input_feat=\"intensity\",\n",
    "        voxel_size=0.1,\n",
    "        train_augmentations=None,\n",
    "        dim_proj=[\n",
    "            0,\n",
    "        ],\n",
    "        grids_shape=[(256, 256)],\n",
    "        fov_xyz=(\n",
    "            (-1.0, -1.0, -1.0),\n",
    "            (1.0, 1.0, 1.0),\n",
    "        ),\n",
    "        num_neighbors=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dataset split\n",
    "        self.phase = phase\n",
    "        assert self.phase in [\"train\", \"val\", \"trainval\", \"test\"]\n",
    "\n",
    "        # Root directory of dataset\n",
    "        self.rootdir = rootdir\n",
    "\n",
    "        # Input features to compute for each point\n",
    "        self.input_feat = input_feat\n",
    "\n",
    "        # Downsample input point cloud by small voxelization\n",
    "        self.downsample = tr.Voxelize(\n",
    "            dims=(0, 1, 2),\n",
    "            voxel_size=voxel_size,\n",
    "            random=(self.phase == \"train\" or self.phase == \"trainval\"),\n",
    "        )\n",
    "\n",
    "        # Field of view\n",
    "        assert len(fov_xyz[0]) == len(\n",
    "            fov_xyz[1]\n",
    "        ), \"Min and Max FOV must have the same length.\"\n",
    "        for i, (min, max) in enumerate(zip(*fov_xyz)):\n",
    "            assert (\n",
    "                min < max\n",
    "            ), f\"Field of view: min ({min}) < max ({max}) is expected on dimension {i}.\"\n",
    "        self.fov_xyz = np.concatenate([np.array(f)[None] for f in fov_xyz], axis=0)\n",
    "        self.crop_to_fov = tr.Crop(dims=(0, 1, 2), fov=fov_xyz)\n",
    "\n",
    "        # Grid shape for projection in 2D\n",
    "        assert len(grids_shape) == len(dim_proj)\n",
    "        self.dim_proj = dim_proj\n",
    "        self.grids_shape = [np.array(g) for g in grids_shape]\n",
    "        self.lut_axis_plane = {0: (1, 2), 1: (0, 2), 2: (0, 1)}\n",
    "\n",
    "        # Number of neighbors for embedding layer\n",
    "        assert num_neighbors > 0\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        # Train time augmentations\n",
    "        if train_augmentations is not None:\n",
    "            assert self.phase in [\"train\", \"trainval\"]\n",
    "        self.train_augmentations = train_augmentations\n",
    "        \n",
    "        self.list_frames = [\"Lille1_1.ply\"] # ,  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",\n",
    "        self.mean_int = 18.705505\n",
    "        self.std_int = 23.756725\n",
    "\n",
    "    def get_occupied_2d_cells(self, pc):\n",
    "        \"\"\"Return mapping between 3D point and corresponding 2D cell\"\"\"\n",
    "        cell_ind = []\n",
    "        for dim, grid in zip(self.dim_proj, self.grids_shape):\n",
    "            # Get plane of which to project\n",
    "            dims = self.lut_axis_plane[dim]\n",
    "            # Compute grid resolution\n",
    "            res = (self.fov_xyz[1, dims] - self.fov_xyz[0, dims]) / grid[None]\n",
    "            # Shift and quantize point cloud\n",
    "            pc_quant = ((pc[:, dims] - self.fov_xyz[0, dims]) / res).astype(\"int\")\n",
    "            # Check that the point cloud fits on the grid\n",
    "            min, max = pc_quant.min(0), pc_quant.max(0)\n",
    "            assert min[0] >= 0 and min[1] >= 0, print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            assert max[0] < grid[0] and max[1] < grid[1], print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            # Transform quantized coordinates to cell indices for projection on 2D plane\n",
    "            temp = pc_quant[:, 0] * grid[1] + pc_quant[:, 1]\n",
    "            cell_ind.append(temp[None])\n",
    "        return np.vstack(cell_ind)\n",
    "\n",
    "    def prepare_input_features(self, pc_orig):\n",
    "        # Concatenate desired input features to coordinates\n",
    "        pc = [pc_orig[:, :3]]  # Initialize with coordinates\n",
    "        for type in self.input_feat:\n",
    "            if type == \"intensity\":\n",
    "                intensity = pc_orig[:, 3:]\n",
    "                intensity = (intensity - self.mean_int) / self.std_int\n",
    "                pc.append(intensity)\n",
    "            elif type == \"height\":\n",
    "                pc.append(pc_orig[:, 2:3])\n",
    "            elif type == \"radius\":\n",
    "                r_xyz = np.linalg.norm(pc_orig[:, :3], axis=1, keepdims=True)\n",
    "                pc.append(r_xyz)\n",
    "            elif type == \"xyz\":\n",
    "                xyz = pc_orig[:, :3]\n",
    "                pc.append(xyz)\n",
    "            elif type == \"constant\":\n",
    "                pc.append(np.ones((pc_orig.shape[0], 1)))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature: {type}\")\n",
    "        return np.concatenate(pc, 1)\n",
    "\n",
    "    def load_pc(self, index):\n",
    "        fname = os.path.join(self.rootdir, \"training_10_classes\", self.list_frames[index])\n",
    "        plydata = PlyData.read(fname)\n",
    "        x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "        y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "        z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "        reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "        #print(x.shape[0])\n",
    "        feats = np.zeros((x.shape[0], 1))\n",
    "        label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "        label = label-1\n",
    "        pts = np.concatenate([\n",
    "            np.expand_dims(x,1),\n",
    "            np.expand_dims(y,1),\n",
    "            np.expand_dims(z,1),\n",
    "            np.expand_dims(reflectance,1),\n",
    "            feats,\n",
    "        ], axis=1).astype(np.float32)\n",
    "        \n",
    "        return pts, np.expand_dims(label,1), self.list_frames[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_frames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load original point cloud\n",
    "        pc_orig, labels_orig, filename = self.load_pc(index)\n",
    "\n",
    "        # Prepare input feature\n",
    "        pc_orig = self.prepare_input_features(pc_orig)\n",
    "\n",
    "        # Voxelization\n",
    "        pc, labels = self.downsample(pc_orig, labels_orig)\n",
    "\n",
    "        # Augment data\n",
    "        if self.train_augmentations is not None:\n",
    "            pc, labels = self.train_augmentations(pc, labels)\n",
    "\n",
    "        # Crop to fov\n",
    "        pc, labels = self.crop_to_fov(pc, labels)\n",
    "\n",
    "        # For each point, get index of corresponding 2D cells on projected grid\n",
    "        cell_ind = self.get_occupied_2d_cells(pc)\n",
    "\n",
    "        # Get neighbors for point embedding layer providing tokens to waffleiron backbone\n",
    "        kdtree = KDTree(pc[:, :3])\n",
    "        assert pc.shape[0] > self.num_neighbors\n",
    "        dist, neighbors_emb = kdtree.query(pc[:, :3], k=self.num_neighbors + 1)\n",
    "\n",
    "        # Nearest neighbor interpolation to undo cropping & voxelisation at validation time\n",
    "        if self.phase in [\"train\", \"trainval\"]:\n",
    "            upsample = np.arange(pc.shape[0])\n",
    "        else:\n",
    "            _, upsample = kdtree.query(pc_orig[:, :3], k=1)\n",
    "\n",
    "        # Output to return\n",
    "        out = (\n",
    "            # Point features\n",
    "            pc[:, 3:].T[None],\n",
    "            # Point labels of original entire point cloud\n",
    "            labels if self.phase in [\"train\", \"trainval\"] else labels_orig,\n",
    "            # Projection 2D -> 3D: index of 2D cells for each point\n",
    "            cell_ind[None],\n",
    "            # Neighborhood for point embedding layer, which provides tokens to waffleiron backbone\n",
    "            neighbors_emb.T[None],\n",
    "            # For interpolation from voxelized & cropped point cloud to original point cloud\n",
    "            upsample,\n",
    "            # Filename of original point cloud\n",
    "            filename,\n",
    "        )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "337afe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, num_points=None):\n",
    "        self.num_points = num_points\n",
    "        assert num_points is None or num_points > 0\n",
    "\n",
    "    def __call__(self, list_data):\n",
    "\n",
    "        # Extract all data\n",
    "        list_of_data = (list(data) for data in zip(*list_data))\n",
    "        feat, label_orig, cell_ind, neighbors_emb, upsample, filename = list_of_data\n",
    "\n",
    "        # Zero-pad point clouds\n",
    "        Nmax = np.max([f.shape[-1] for f in feat])\n",
    "        if self.num_points is not None:\n",
    "            assert Nmax <= self.num_points\n",
    "        occupied_cells = []\n",
    "        for i in range(len(feat)):\n",
    "            feat[i], neighbors_emb[i], cell_ind[i], temp = zero_pad(\n",
    "                feat[i],\n",
    "                neighbors_emb[i],\n",
    "                cell_ind[i],\n",
    "                Nmax if self.num_points is None else self.num_points,\n",
    "            )\n",
    "            occupied_cells.append(temp)\n",
    "\n",
    "        # Concatenate along batch dimension\n",
    "        feat = torch.from_numpy(np.vstack(feat)).float()  # B x C x Nmax\n",
    "        neighbors_emb = torch.from_numpy(np.vstack(neighbors_emb)).long()  # B x Nmax\n",
    "        cell_ind = torch.from_numpy(\n",
    "            np.vstack(cell_ind)\n",
    "        ).long()  # B x nb_2d_cells x Nmax\n",
    "        occupied_cells = torch.from_numpy(np.vstack(occupied_cells)).float()  # B x Nmax\n",
    "        labels_orig = torch.from_numpy(np.hstack(label_orig)).long()\n",
    "        upsample = [torch.from_numpy(u) for u in upsample]\n",
    "\n",
    "        # Prepare output variables\n",
    "        out = {\n",
    "            \"feat\": feat,\n",
    "            \"neighbors_emb\": neighbors_emb,\n",
    "            \"upsample\": upsample,\n",
    "            \"labels_orig\": labels_orig,\n",
    "            \"cell_ind\": cell_ind,\n",
    "            \"occupied_cells\": occupied_cells,\n",
    "            \"filename\": filename,\n",
    "        }\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1814ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(feat, neighbors_emb, cell_ind, Nmax):\n",
    "    N = feat.shape[-1]\n",
    "    assert N <= Nmax\n",
    "    occupied_cells = np.ones((1, Nmax))\n",
    "    if N < Nmax:\n",
    "        # Zero-pad with null features\n",
    "        feat = np.concatenate((feat, np.zeros((1, feat.shape[1], Nmax - N))), axis=2)\n",
    "        # For zero-padded points, associate last zero-padded points as neighbor\n",
    "        neighbors_emb = np.concatenate(\n",
    "            (\n",
    "                neighbors_emb,\n",
    "                (Nmax - 1) * np.ones((1, neighbors_emb.shape[1], Nmax - N)),\n",
    "            ),\n",
    "            axis=2,\n",
    "        )\n",
    "        # Associate zero-padded points to first 2D cell...\n",
    "        cell_ind = np.concatenate(\n",
    "            (cell_ind, np.zeros((1, cell_ind.shape[1], Nmax - N))), axis=2\n",
    "        )\n",
    "        # ... and at the same time mark zero-padded points as unoccupied\n",
    "        occupied_cells[:, N:] = 0\n",
    "    return feat, neighbors_emb, cell_ind, occupied_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3bad12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"rootdir\": '/root/main/dataset/',\n",
    "        \"input_feat\": [\"xyz\", \"intensity\"],\n",
    "        \"voxel_size\": 5,\n",
    "        \"num_neighbors\": 16,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, 40], [64, 64, 60]], # Check here\n",
    "    }\n",
    "\n",
    "train_dataset = PCDataset(\n",
    "        phase=\"val\",\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1dae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce92bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it, batch in enumerate(train_loader):\n",
    "    \n",
    "    if it == 0:\n",
    "\n",
    "        # Network inputs\n",
    "        #print(batch[\"upsample\"])\n",
    "        feat = batch[\"feat\"].cuda(0, non_blocking=True)\n",
    "        labels = batch[\"labels_orig\"].cuda(0, non_blocking=True)\n",
    "        batch[\"upsample\"] = [\n",
    "            up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "        ]\n",
    "        cell_ind = batch[\"cell_ind\"].cuda(0, non_blocking=True)\n",
    "        occupied_cell = batch[\"occupied_cells\"].cuda(0, non_blocking=True)\n",
    "        neighbors_emb = batch[\"neighbors_emb\"].cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(*net_inputs)\n",
    "        \n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41f2e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 682])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffb61411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
      "        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
      "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
      "        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
      "        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
      "        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
      "        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
      "        616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
      "        630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
      "        644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
      "        658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n",
      "        672, 673, 674, 675, 676, 677, 678, 679, 680, 681], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Voxels to points\n",
    "out_upsample = []\n",
    "for id_b, closest_point in enumerate(batch[\"upsample\"]):\n",
    "    print(id_b)\n",
    "    print(closest_point)\n",
    "    temp = out[id_b, :, closest_point]\n",
    "    out_upsample.append(temp.T)\n",
    "out_2 = torch.cat(out_upsample, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25ee03ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-301.1215,  381.1870, -277.4354,  ...,  -51.7141,  693.8174,\n",
       "         -152.2836],\n",
       "        [-261.3066,  388.1064, -309.1762,  ...,  -12.8059,  628.5758,\n",
       "         -185.1240],\n",
       "        [-224.5502,  445.8945, -319.3336,  ...,  -66.8504,  622.9425,\n",
       "         -237.0106],\n",
       "        ...,\n",
       "        [ 502.3618, -735.2126, -126.4926,  ...,   89.5417,  267.1917,\n",
       "         -178.0704],\n",
       "        [ 502.5536, -729.7637,  -40.1202,  ...,  117.8564,  238.1745,\n",
       "         -209.6077],\n",
       "        [ 496.7866, -618.2017,  -71.5352,  ...,   78.0971,  328.3349,\n",
       "         -162.1528]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc098256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([682, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DLabelProp",
   "language": "python",
   "name": "3dlabelprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
