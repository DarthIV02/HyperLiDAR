apiVersion: apps/v1
kind: Deployment
metadata:
  name: one-for-all
  labels:
    k8s-app: one-for-all
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: one-for-all
  template:
    metadata: 
      labels:
        k8s-app: one-for-all
    spec:
      containers:
      - name: one-for-all-pod
        image: ghcr.io/darthiv02/knowledge_distill:1.0
        command: ["sleep", "infinity"]
        volumeMounts:
          - mountPath: /mnt/data
            name: ivannia-volume-clone
          - mountPath: /root/main
            name: temp-ivannia-volume
          - mountPath: /dev/shm
            name: cache-volume
        resources:
          limits:
            memory: "32G"
            cpu: "2"
            ephemeral-storage: "120Gi"
            nvidia.com/gpu: 4
          requests:
             memory: "24G"
             cpu: "1"
             ephemeral-storage: "80Gi"
             nvidia.com/gpu: 4
      volumes:
        - name: ivannia-volume-clone
          persistentVolumeClaim:
            claimName: ivannia-volume-clone
        - name: temp-ivannia-volume
          persistentVolumeClaim:
            claimName: temp-ivannia-volume
        - emptyDir:
            medium: Memory
          name: cache-volume
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A10
                #- NVIDIA-GeForce-RTX-3090
                #- Tesla-V100-SXM2-32GB