apiVersion: batch/v1
kind: Job
metadata:
  name: lr-job-36
spec:
  template:
    spec:
      containers:
      - name: lr-job-36
        image: nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04
        command: ["/bin/sh", "-c"]
        args:
          - cd /root/main && bash initial_setup.sh;
            eval "$(/root/anaconda3/bin/conda shell.bash hook)";
            conda create -y -n env python=3.8;
            conda activate env;
            git clone https://github.com/DarthIV02/HyperLiDAR.git /home/HyperLiDAR;
            cd /home/HyperLiDAR;
            bash nautilus/3dlabelprop_setup.sh;
            git clone https://github.com/valeoai/WaffleIron;
            pip install -e WaffleIron/;
            wget https://github.com/valeoai/ScaLR/releases/download/v0.1.0/info_datasets.tar.gz;
            tar -xvzf info_datasets.tar.gz;
            rm info_datasets.tar.gz;
            python scalr_and_hd.py --seed 0 -stop 36 --add_lr;
        volumeMounts:
          - mountPath: /root/main
            name: temp-ivannia-volume
          - mountPath: /dev/shm
            name: cache-volume
        resources:
          limits:
            memory: "15G"
            cpu: "1"
            ephemeral-storage: "2Ti"
            nvidia.com/gpu: 1
          requests:
             memory: "12G"
             cpu: "1"
             ephemeral-storage: "1Ti"
             nvidia.com/gpu: 1
      volumes:
        - name: temp-ivannia-volume
          persistentVolumeClaim:
            claimName: temp-ivannia-volume
        - emptyDir:
            medium: Memory
          name: cache-volume
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A10
                #- NVIDIA-GeForce-RTX-3090
                #- Tesla-V100-SXM2-32GB
      restartPolicy: Never
  backoffLimit: 2  