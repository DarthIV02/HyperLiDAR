apiVersion: batch/v1
kind: Job
metadata:
  name: scalr-job
spec:
  template:
    spec:
      containers:
      - name: scalr-job
        image: nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04
        command: 
        - "python"
        args: 
          - "/home/HyperLiDAR/hd_train"
        volumeMounts:
          - mountPath: /root/main
            name: temp-ivannia-volume
          - mountPath: /dev/shm
            name: cache-volume
        resources:
          limits:
            memory: "15G"
            cpu: "1"
            ephemeral-storage: "2Ti"
          requests:
             memory: "12G"
             cpu: "1"
             ephemeral-storage: "1Ti"
      initContainers:
      - name: setup
        image: nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04
        command: ["/bin/sh", "-c"]
        args:
          - cd /root/main && bash initial_setup.sh;
            eval "$(/opt/conda/bin/conda shell.bash hook)";
            conda create -y -n env python=3.8;
            conda activate env;
            git clone https://github.com/DarthIV02/HyperLiDAR.git /home/HyperLiDAR;
            cd /home/HyperLiDAR;
            bash nautilus/3dlabelprop_setup.sh;
        volumeMounts:
          - mountPath: /root/main
            name: temp-ivannia-volume
      volumes:
        - name: temp-ivannia-volume
          persistentVolumeClaim:
            claimName: temp-ivannia-volume
        - emptyDir:
            medium: Memory
          name: cache-volume
      #affinity:
      #  nodeAffinity:
      #    requiredDuringSchedulingIgnoredDuringExecution:
      #      nodeSelectorTerms:
      #      - matchExpressions:
      #        - key: nvidia.com/gpu.product
      #          operator: In
      #          values:
      #          - NVIDIA-A10
                #- NVIDIA-GeForce-RTX-3090
                #- Tesla-V100-SXM2-32GB
      restartPolicy: Never
  backoffLimit: 2  