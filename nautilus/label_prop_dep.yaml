apiVersion: apps/v1
kind: Deployment
metadata:
  name: scalr-pod
  labels:
    k8s-app: scalr-pod
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: scalr-pod
  template:
    metadata: 
      labels:
        k8s-app: scalr-pod
    spec:
      containers:
      - name: scalr-pod
        image: nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04
        command: ["sleep", "infinity"]
        volumeMounts:
          - mountPath: /mnt/data
            name: ivannia-volume-clone
          - mountPath: /root/main
            name: temp-ivannia-volume
          - mountPath: /dev/shm
            name: cache-volume
        resources:
          limits:
            memory: "64G"
            cpu: "4"
            ephemeral-storage: "2Ti"
            nvidia.com/gpu: 1
          requests:
             memory: "12G"
             cpu: "1"
             ephemeral-storage: "1Ti"
             nvidia.com/gpu: 1
      volumes:
        - name: ivannia-volume-clone
          persistentVolumeClaim:
            claimName: ivannia-volume-clone
        - name: temp-ivannia-volume
          persistentVolumeClaim:
            claimName: temp-ivannia-volume
        - emptyDir:
            medium: Memory
          name: cache-volume
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A10
                #- NVIDIA-GeForce-RTX-3090
                #- Tesla-V100-SXM2-32GB